{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28dbb055",
   "metadata": {
    "id": "28dbb055"
   },
   "source": [
    "# APPM 5720 DeepGreen Example Notebook\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mikemccabe210/appm5720_dg_demo/blob/main/DeepGreenDemo.ipynb)\n",
    "#### Paper: DeepGreen: deep learning of Greenâ€™s functions for nonlinear boundary value problems\n",
    "#### Paper by: Craig R. Gin, Daniel E. Shea, Steven L. Brunton, and J. Nathan Kutz\n",
    "#### Notebook by: Rey Koki and Mike McCabe\n",
    "\n",
    "This notebook walks through the nonlinear Poisson problem from _DeepGreen_. Several steps are slightly simplified from the original code, which can be found here: https://github.com/sheadan/DeepGreen, since we're only implementing one example and do not need the fully general code. We also make a few small departures for efficiency/speed purposes. These will be pointed out when they come up.\n",
    "\n",
    "## Nonlinear Poisson\n",
    "\n",
    "Put the problem description here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "083b497f",
   "metadata": {
    "id": "083b497f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used gpu\n"
     ]
    }
   ],
   "source": [
    "# Imports!\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.random as rnd\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "import flax.linen as nn\n",
    "import functools\n",
    "import matplotlib.pyplot as plt\n",
    "from flax.training import train_state, checkpoints\n",
    "from flax.metrics import tensorboard\n",
    "from random import shuffle, seed\n",
    "from typing import Sequence, Callable, Any, Optional, Dict\n",
    "from jax.lib import xla_bridge\n",
    "print('Device used', xla_bridge.get_backend().platform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcb43d8",
   "metadata": {
    "id": "bfcb43d8"
   },
   "source": [
    "## Defining the Neural Network\n",
    "\n",
    "Here we define the neural network. Here, we use the Flax library built on top of JAX. JAX is an automatic differentiation and linear algebra acceleration library developed by Google. The API is intended to mimic numpy, though it has the added capability for functional transformations like computing gradients, automatically vectorizing code, or just-in-time (JIT) compiling it down to XLA code.\n",
    "\n",
    "Flax tends to have quite a bit of complexity hidden behind the scenes which makes it a bit harder to use than comparable libraries like PyTorch. Looking through the code below, it might seem like some things are being instantiated every time the model is called, but in practice, these objects are traced when they are instantiated and the actual object being behaves slightly differently. \n",
    "\n",
    "The model itself consists of two sets of encoders/decoders with the linear operator acting as a coupling mechanism in the encoding space. We start off by defining the Encoder and Decoder templates:\n",
    "\n",
    "__We didn't directly parameterize the encoder/decoders in DeepGreen for this demo, so to adjust the layers/depth/activations you'll have to do it directly (or adjust the code to pass parameters to the inner modules. If you adjust the layer count, you also need to adjust the downsampling factor in GreenNet to use custom resolutions (values of n).__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d06c81cc",
   "metadata": {
    "id": "d06c81cc"
   },
   "outputs": [],
   "source": [
    "class Conv2DEncoder(nn.Module):\n",
    "    # This is a DataClass, so these implicitly define init parameters\n",
    "    num_filters: Sequence[int] = (8, 16, 32, 64)\n",
    "    conv_window: Sequence[int] = (4, 4)\n",
    "    conv_strides: int = (1,1)\n",
    "    conv_padding: str = 'SAME'\n",
    "    pool_window: Sequence[int] = (2, 2)\n",
    "    pool_strides: int = (2,2)\n",
    "    pool_padding: str = 'VALID'\n",
    "    act_fn: Callable = nn.relu\n",
    "    add_init_fin: bool = True\n",
    "        \n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        inputs = x[:] # Save copy of inputs for residual        \n",
    "        for i, filters in enumerate(self.num_filters):\n",
    "            if i > 0:\n",
    "                x = nn.avg_pool(x, window_shape=self.pool_window,\n",
    "                                strides=self.pool_strides,\n",
    "                               padding=self.pool_padding)\n",
    "            x = nn.Conv(features=filters, kernel_size=self.conv_window,\n",
    "                       strides=self.conv_strides, padding=self.conv_padding)(x)\n",
    "            x = self.act_fn(x)\n",
    "            # If residual included, add projected inputs\n",
    "        if self.add_init_fin:\n",
    "            inputs = nn.Conv(features=self.num_filters[-1], \n",
    "                        kernel_size=(2**(len(self.num_filters)-1),)*2,\n",
    "                         strides=(2**(len(self.num_filters)-1),)*2,\n",
    "                        padding='VALID')(inputs)\n",
    "\n",
    "            x += inputs\n",
    "        return x.reshape(x.shape[0], -1)\n",
    "                \n",
    "    \n",
    "class Conv2DDecoder(nn.Module):\n",
    "    init_size: Sequence[int] = (16, 16, 64)\n",
    "    output_size: Sequence[int] = (-1, 128, 128)\n",
    "    num_filters: Sequence[int] = (32, 16, 8)\n",
    "    conv_window: Sequence[int] = (4, 4)\n",
    "    conv_strides:int = (2,2)\n",
    "    conv_padding: str = 'SAME'\n",
    "    act_fn: Callable = nn.relu\n",
    "    add_init_fin: bool = True\n",
    "        \n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = x.reshape(-1, *self.init_size)\n",
    "        inputs = x[:]\n",
    "        for filters in self.num_filters:\n",
    "            x = nn.ConvTranspose(features=filters, kernel_size=self.conv_window,\n",
    "                                 strides=self.conv_strides, padding=self.conv_padding)(x)\n",
    "            x = self.act_fn(x)\n",
    "        # Do one last small convolution\n",
    "        x = nn.ConvTranspose(features=1,\n",
    "                             kernel_size=self.conv_window,\n",
    "                            strides=(1,1),\n",
    "                            padding=self.conv_padding)(x).squeeze(-1)\n",
    "        \n",
    "        # Note this a departure from the actual paper code\n",
    "        # which just reshapes the encoder space to add. Since\n",
    "        # that makes no sense (it's like trying to add a smaller color\n",
    "        # image to a larger greyscale image by shifting the RGB values to different\n",
    "        # pixels to make the shapes line up), we've swapped to standard upsampling\n",
    "        if self.add_init_fin:\n",
    "            inputs = nn.Conv(features=1, kernel_size=(1, 1))(inputs).squeeze(-1)\n",
    "            inputs = jax.image.resize(inputs, shape=(inputs.shape[0], *self.output_size[1:]), method='linear')\n",
    "            x += inputs\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634377d0",
   "metadata": {
    "id": "634377d0"
   },
   "source": [
    "Once the encoders and decoders are built, the full model just connects the encoder/decoder pairs through a few linear projections and the linear operator. The sequential linear operations are a little unconventional as these are essentially a single low-rank linear operator though with the coupling $Lv=f$/$L^{-1}f=v$ promoted by the loss function.\n",
    "\n",
    "Note that we return all values included in loss functions. In applications, one would likely only be using the trained model to infer $u$ from $f$ and as such would not require all outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50eb2a30",
   "metadata": {
    "id": "50eb2a30"
   },
   "outputs": [],
   "source": [
    "class GreenNet(nn.Module):\n",
    "    # Note, since we're only doing the nonlinear Poisson example,\n",
    "    # we removed some of the parameterization here to simplify things\n",
    "    n: int = 128\n",
    "    units_latent: int = 200    \n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, inputs):\n",
    "        u, F = inputs\n",
    "        \n",
    "        # Let's define our modules. Since we reuse them, it probably would have\n",
    "        # made more sense to not use nn.compact and just use a setup function\n",
    "        # but it is too late now. This is getting traced anyway,\n",
    "        # so it doesn't actually matter apart from looking a bit clunky.\n",
    "        u_encoder = Conv2DEncoder()\n",
    "        u_decoder = Conv2DDecoder(output_size=(-1, self.n, self.n), init_size=(self.n//8, self.n//8, 64))\n",
    "        v_reducer = nn.Dense(self.units_latent)\n",
    "        v_expander = nn.Dense(self.n**2)\n",
    "        \n",
    "        F_encoder = Conv2DEncoder()\n",
    "        F_decoder = Conv2DDecoder(output_size=(-1, self.n, self.n), init_size=(self.n//8, self.n//8, 64))\n",
    "        f_reducer = nn.Dense(self.units_latent)\n",
    "        f_expander = nn.Dense(self.n**2)\n",
    "        \n",
    "        operator = self.param('Operator', init_fn=lambda key: jnp.eye(self.units_latent)*1.)\n",
    "\n",
    "        # Autoencode u\n",
    "        u_encoded = u_encoder(u)\n",
    "        # I guess this avoids doing a large dense matrix inverse\n",
    "        v = v_reducer(u_encoded)\n",
    "        v_exp = v_expander(v)\n",
    "        u_decoded = u_decoder(v_exp)\n",
    "        \n",
    "        # Autoencode F\n",
    "        F_encoded = F_encoder(F)\n",
    "        f = f_reducer(F_encoded)\n",
    "        f_exp = f_expander(f)\n",
    "        F_decoded = F_decoder(f_exp)  \n",
    "        \n",
    "        # L things - seems kind of wasteful, but L is small\n",
    "        L_upper = jnp.triu(operator)\n",
    "        L = .5*(L_upper+L_upper.T)\n",
    "        \n",
    "        # Forward model\n",
    "        Lv = jax.lax.dot_general(v, L,\n",
    "                                 (((v.ndim - 1,), (0,)), ((), ())),)\n",
    "        Lv_exp = f_expander(Lv)\n",
    "        Lv_decoded = F_decoder(Lv_exp)\n",
    "        \n",
    "        # Inverse model\n",
    "        Linvf = jnp.linalg.solve(jnp.expand_dims(L, 0), f)\n",
    "        Linvf_exp = f_expander(Linvf)\n",
    "        Linvf_decoded = F_decoder(Linvf_exp)\n",
    "        \n",
    "        return u_decoded, F_decoded, Lv_decoded, Linvf_decoded, f, v, Lv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dff1b0",
   "metadata": {
    "id": "55dff1b0"
   },
   "source": [
    "## Building the data set\n",
    "\n",
    "We handle data a bit differently from the paper to avoid forcing everyone to download several GB of data. The paper generated data by sampling forcing functions and using an external solver to generate solutions. This is time consuming and doesn't actually compute the exact loss. We instead use the Method of Manufactured Solutions (MMS) so that we can generate solutions and forcings in real time.\n",
    "\n",
    "As opposed to computing true solutions for given forcings, in MMS, you sample solutions and compute the forcing by applying the differential operator to the solution. While this doesn't always result in realistic problems and generally requires smooth solutions, it is much, much faster and more accurate than generating data from numerical solvers. The downside is that using their forcings as solutions breaks boundary conditions which isn't ideal given the proposal is to learn a Green's function in the encoder space, so we changed some of the functions up to ensure homogeneous BCs. \n",
    "\n",
    "This data API here is a little weird - the original version was too slow for demo purposes, so the final version is a mix between the original version (which used a more standard data API) and a JIT-friendly data API. The test/train split components are the main victims here as they ultimately got hard-coded with some unnecessary storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bd143ed1",
   "metadata": {
    "id": "bd143ed1"
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "def nlp_operator(u):\n",
    "    \"\"\" Transforms function by applying the nonlinear Poisson operator:\n",
    "      \n",
    "        Pu = -\\nabla \\dot ((1+u^2)\\nabla u)\n",
    "    \"\"\"\n",
    "    flux = lambda x: (1+u(x)**2)*(jax.grad(u)(x))\n",
    "    return lambda x: (-jax.jacfwd(flux)(x)*jnp.eye(2)).sum()\n",
    "    \n",
    "def jax_collate(batch):\n",
    "    if isinstance(batch[0], jnp.DeviceArray):\n",
    "        return jnp.stack(batch)\n",
    "    elif isinstance(batch[0], (tuple,list)):\n",
    "        transposed = zip(*batch)\n",
    "        return [jax_collate(samples) for samples in transposed]\n",
    "    else:\n",
    "        return jnp.array(batch)\n",
    "    \n",
    "def NLP_Dataset_Sampler(n=128, batch_size=64, cubic=False, train=True, valid=False, test=False):\n",
    "    \"\"\" Factory for building data samplers for training.\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    n ~ int: Number of grid points in the x and y directions\n",
    "    batch size ~ int: Examples per batch.\n",
    "    cubic ~ bool: Indicator whether to sample from the cubic space\n",
    "    train ~ bool: Indicator whether to use the train indices\n",
    "    valid ~ bool: Indicator whether to use the validation indices\n",
    "    test ~ bool: Indicator whether to use the (non-cubic) test indices\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    sampler ~ Callable: takes in indices and returns data\n",
    "    len_func ~ Callable: zero parameter function that returns the dataset size.\n",
    "    \"\"\"\n",
    "    ##### u, F Builder Functions ######\n",
    "    def gamma(k):\n",
    "        return .01 +.28*k/3\n",
    "              \n",
    "    def build_gaussian(params):\n",
    "        # Just multiplied by sin to get BCs\n",
    "        a, bx, by, c = params\n",
    "        u = lambda x: .01*a*jnp.exp((-(x[0]-bx)**2 - (x[1]-by)**2)/(2*c**2))*jnp.sin(.5*x[0])*jnp.sin(.5*x[1])\n",
    "        F = nlp_operator(u)\n",
    "        Um, Fm = jax.vmap(u), jax.vmap(F)\n",
    "        return Um(coords), Fm(coords)\n",
    "    \n",
    "    def build_cosine(params):\n",
    "        # Actually sines\n",
    "        alpha, betax, betay, _ = params \n",
    "        u = lambda x: .01*alpha*jnp.sin(betax*x[0])*jnp.sin(betay*x[1])\n",
    "        F = nlp_operator(u)\n",
    "        Um, Fm = jax.vmap(u), jax.vmap(F)\n",
    "        return Um(coords), Fm(coords)\n",
    "    \n",
    "    \n",
    "    def build_cubic1(params):\n",
    "        # Moved 0s\n",
    "        kx, ky, _, _ = params\n",
    "        u = lambda x: .01*(kx*(x[0]-jnp.pi)*(x[0]-2*jnp.pi)*x[0] \\\n",
    "                        + ky*(x[1]-jnp.pi)*(x[1]-2*jnp.pi)*x[1])\n",
    "        F = nlp_operator(u)\n",
    "        Um, Fm = jax.vmap(u), jax.vmap(F)\n",
    "        return Um(coords), Fm(coords)\n",
    "    \n",
    "    def build_cubic2(params):\n",
    "        # Moved 0s and removed psi\n",
    "        kx, ky, zetax, zetay = params\n",
    "        u = lambda x: .01*(kx*(x[0]-jnp.pi)*(x[0]-2*jnp.pi)*x[0] + ky*(x[1]-jnp.pi)*(x[1]-2*jnp.pi)*x[1] \\\n",
    "                        + zetax*(x[0]-2*jnp.pi)*x[0] + zetay*(x[1]-2*jnp.pi)*x[1])\n",
    "        F = nlp_operator(u)\n",
    "        Um, Fm = jax.vmap(u), jax.vmap(F)\n",
    "        return Um(coords), Fm(coords)\n",
    "\n",
    "    ##### Actual Sampling functions #####\n",
    "    def get_len():\n",
    "        return len(data)\n",
    "    \n",
    "    def get_item(idx):\n",
    "        sub = data[idx]\n",
    "        func_build, params = sub[0], sub[1:]\n",
    "        u, F = jax.lax.switch(func_build.astype(int), [build_gaussian, build_cosine,\n",
    "                                                      build_cubic1, build_cubic2], params) \n",
    "        return u.reshape(n, n, 1), F.reshape(n, n, 1)\n",
    "    \n",
    "    sample = jax.vmap(get_item)\n",
    "    \n",
    "    # Build shared state for all inner functions\n",
    "    if not cubic:\n",
    "        # Set up Gaussians\n",
    "        a_range = jnp.arange(-25, 26., 5)\n",
    "        b_range = jnp.arange(jnp.pi/3, 5*jnp.pi/3+.01, jnp.pi/3)\n",
    "        c_range = jnp.arange(.1, 5, .2)\n",
    "        gauss_params = [(0.,)+ p for p in product(a_range, b_range, b_range, c_range)]\n",
    "\n",
    "        alpha_range = jnp.arange(1, 10.1, .1)\n",
    "        beta_range = jnp.arange(1, 5.1, .5)\n",
    "        cosine_params = [(1.,)+ p+(0,) \n",
    "                         for p in product(alpha_range, beta_range, beta_range)]\n",
    "\n",
    "        total_params = gauss_params + cosine_params\n",
    "        seed(1)\n",
    "        shuffle(total_params)\n",
    "\n",
    "        # Hard coding the values from the paper even though it's not the same\n",
    "        if train:\n",
    "            data = total_params[:9806]\n",
    "        elif valid:\n",
    "            data = total_params[9806:9806+2452]\n",
    "        else:\n",
    "            data = total_params[9806+2452:]\n",
    "\n",
    "    else:\n",
    "        k = gamma(jnp.array([0, 1, 2, 3]))\n",
    "        zeta = jnp.arange(.01, .26, .6)\n",
    "        cubic1_params = [(2.,) + p+(0,0)\n",
    "                       for p in product(k, k)]\n",
    "        cubic2_params = [(3.,) + p\n",
    "                       for p in product(k, k, zeta, zeta)]\n",
    "        data = cubic1_params + cubic2_params\n",
    "\n",
    "    data = jnp.array(data)\n",
    "    # Build the mesh once and reuse\n",
    "    xx, yy = jnp.meshgrid(jnp.linspace(0, 2*jnp.pi, n), jnp.linspace(0, 2*jnp.pi, n))\n",
    "    coords = jnp.stack([xx, yy], -1).reshape(-1, 2)\n",
    "    \n",
    "    return jax.jit(sample), get_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c717765",
   "metadata": {
    "id": "2c717765"
   },
   "source": [
    "## Setting up the run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a538548",
   "metadata": {
    "id": "7a538548"
   },
   "source": [
    "Now we'll define the training loops. The paper uses multiple parallel runs and takes the best performing models. This is going to be running on Colab so you are not going to have the hardware for that. Instead, we're just going to train a single model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f560cf10",
   "metadata": {
    "id": "f560cf10"
   },
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def update_params(state, grads):\n",
    "    return state.apply_gradients(grads=grads)\n",
    "\n",
    "        \n",
    "@jax.jit\n",
    "def compute_losses(u, F, u_decoded, F_decoded, Lv_decoded, Linvf_decoded, f, v, Lv, eps=1e-5):\n",
    "    \"\"\" Computes the 6 Normalized MSEs from the paper.\n",
    "    \n",
    "    Note: the use of means instead of sums in computing squared norms is from the paper\n",
    "    code. They also sum over batches. This doesn't matter that much, but it does adjust the weighting a bit, \n",
    "    so we manually re-weight to account for it.\n",
    "    \"\"\"\n",
    "    # Loss 1 - Reconstruction u\n",
    "    loss1 = (((u_decoded - u)**2).mean((1, 2)) / ((u**2).mean((1,2))+eps)).mean()\n",
    "    # Loss 2 - Reconstruction f \n",
    "    loss2 = (((F_decoded - F)**2).mean((1, 2)) / ((F**2).mean((1,2))+eps)).mean()\n",
    "    # Loss 3 - Forward in encoded space - don't love the gradient dynamics of dividing here\n",
    "    loss3 = (((Lv - f)**2).mean(-1) / ((f**2).mean(-1)+eps)).mean()\n",
    "    # Loss 4 - \"Superposition\" loss - seems like it would just change the relative weight of loss 3 \n",
    "    # in a weird non-convex way and penalize the magnitude of the encoded vectors. Doesn't seem like \n",
    "    # a great idea, but it is in the paper\n",
    "    loss4 = 0.\n",
    "    # Loss 5 - Forward operator loss\n",
    "    loss5 = (((Lv_decoded - F)**2).mean((1, 2)) / ((F**2).mean((1,2))+eps)).mean()\n",
    "    # Loss 6 - Backwards operator loss\n",
    "    loss6 = (((Linvf_decoded - u)**2).mean((1, 2)) / ((u**2).mean((1,2))+eps)).mean()\n",
    "    return loss1, loss2, loss3, loss4, loss5, loss6\n",
    "\n",
    "@functools.partial(jax.jit, static_argnums=(0, 2, 4, 5))\n",
    "def train_epoch(model, state, data, perms, num_batches, eval_full=True):\n",
    "    # JIT is touchy around conditionals (the trace notes the first path), so this just says compile\n",
    "    #  again if the conditional changes. \n",
    "    @functools.partial(jax.jit)\n",
    "    def grad_step(state, perm):\n",
    "        def loss_fn(params):\n",
    "            # Run model\n",
    "            u_decoded, F_decoded, Lv_decoded, Linvf_decoded, f, v, Lv = model.apply({'params':params}, batch)\n",
    "            u, F = batch\n",
    "            u, F = u.squeeze(-1), F.squeeze(-1)\n",
    "            loss1, loss2, loss3, loss4, loss5, loss6 = compute_losses(u, F, u_decoded, F_decoded, \n",
    "                                                                      Lv_decoded, Linvf_decoded, f, v, Lv)\n",
    "            # We're keeping all the losses for logging, but the total loss is only the reconstruction\n",
    "            # losses at the beginning of training\n",
    "            if eval_full:\n",
    "                return loss1+loss2+loss3+loss4+loss5+loss6, (loss1, loss2, loss3, loss4, loss5, loss6)\n",
    "            else:\n",
    "                return loss1+loss2, (loss1, loss2, loss3, loss4, loss5, loss6)\n",
    "        \n",
    "        batch = data(perm)\n",
    "        grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "        (train_loss, aux_losses), grads = grad_fn(state.params)\n",
    "        state = update_params(state, grads)\n",
    "        return state, aux_losses\n",
    "\n",
    "    # Run actual code - Carries and updates state every batch\n",
    "    # returns final state and accumulated outputs (losses)\n",
    "    state, aux_loss_means = jax.lax.scan(grad_step, state, perms)\n",
    "    return state, [jnp.mean(l) for l in aux_loss_means]   \n",
    "\n",
    "def validation_run(model, state, data, batch_size, num_batches):\n",
    "    # Only difference is we do not compute the gradient and update the state here\n",
    "    @functools.partial(jax.jit)\n",
    "    def exec_step(state, perm):\n",
    "        # Run model\n",
    "        batch = data(perm)\n",
    "        u_decoded, F_decoded, Lv_decoded, Linvf_decoded, f, v, Lv = model.apply({'params':state.params}, batch)\n",
    "        u, F = batch\n",
    "        u, F = u.squeeze(-1), F.squeeze(-1)\n",
    "        loss1, loss2, loss3, loss4, loss5, loss6 = compute_losses(u, F, u_decoded, F_decoded, \n",
    "                                                                  Lv_decoded, Linvf_decoded, f, v, Lv)        \n",
    "        return state, (loss1, loss2, loss3, loss4, loss5, loss6)\n",
    "    perms = jnp.arange(batch_size*num_batches).reshape(num_batches, batch_size)\n",
    "    state, aux_loss_means = jax.lax.scan(exec_step, state, perms)\n",
    "    return [jnp.mean(l) for l in aux_loss_means] \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7592d8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model run parameters\n",
    "batch_size = 64\n",
    "n= 128\n",
    "\n",
    "# Content doesn't matter so we're just chosing a convenient shape\n",
    "init_vals = jnp.array(np.random.uniform(size=(10, n, n, 1)))\n",
    "\n",
    "# JAX's random is kind of a pain, but it makes more sense when you're doing distributed training\n",
    "# which we are not doing here. \n",
    "key = rnd.PRNGKey(0)\n",
    "key, use_key = rnd.split(key, 2)\n",
    "\n",
    "model = GreenNet(n=n)\n",
    "params = model.init(use_key, (init_vals, init_vals))\n",
    "\n",
    "# JAX is a functional framework, but Deep Learning has historically used mostly object oriented libraries.\n",
    "# TrainState is a helper for organizing the model parameters and state so the training loop can be written \n",
    "# more like OOP code.\n",
    "\n",
    "# We're using the AdamW optimizer as the paper uses Adam with weight decay. \n",
    "state = train_state.TrainState.create(apply_fn=model.apply,\n",
    "                                     params = params['params'],\n",
    "                                     tx=optax.adamw(learning_rate=1e-3, weight_decay=1e-6))\n",
    "\n",
    "# Load up on datasets - the len funcs instead of objects were just a mistake\n",
    "train_dataset, train_len_func = NLP_Dataset_Sampler(n=n, batch_size=batch_size)\n",
    "valid_dataset, valid_len_func = NLP_Dataset_Sampler(n=n, batch_size=batch_size, train=False, test=True)\n",
    "test_dataset, test_len_func = NLP_Dataset_Sampler(n=n, batch_size=batch_size, train=False, test=True)\n",
    "cubic_test_dataset, cubic_len_func = NLP_Dataset_Sampler(n=n, batch_size=batch_size, cubic=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76d99c6",
   "metadata": {},
   "source": [
    "Before we train the model, let's look in at what functions we're trying to learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7e413d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "u, F = train_dataset(jnp.array([1, 11]))\n",
    "u, F = u.squeeze(-1), F.squeeze(-1)\n",
    "\n",
    "fig = plt.figure(constrained_layout=True, figsize=(6,6))\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 6))\n",
    "axes[0][0].set_title('u Values')\n",
    "axes[0][1].set_title('F Values')\n",
    "aa = axes[0][0].imshow(u[0])\n",
    "plt.colorbar(aa, ax=axes[0][0])\n",
    "ab = axes[0][1].imshow(F[0])\n",
    "plt.colorbar(ab, ax=axes[0][1])\n",
    "ac = axes[1][0].imshow(u[1])\n",
    "plt.colorbar(ac, ax=axes[1][0])\n",
    "ad = axes[1][1].imshow(F[1])\n",
    "plt.colorbar(ad, ax=axes[1][1])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fb1f993c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 32, 32, 1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3141216a",
   "metadata": {},
   "source": [
    "These functions seem a bit harder due to varying scales compared to the paper problems, which from observing their \"hardest\" problems by loss, seemed to have generally had forcings and solutions on the same scale. In our case, there might be several orders of magnitude difference between the two. This makes the optimization problem a bit harder as we'd like all of our losses to have similar magnitude, but that's not going to be possible here without careful reweighting. We had to manually scale them down to reduce the magnitude gaps within individual solutions and forcings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c22967a",
   "metadata": {},
   "source": [
    "## Running the Model\n",
    "\n",
    "Now all that's left is training the model. On the colab GPU with $n=128$ (the setting from the paper), this will take far longer than this class. You can either reduce the size (make sure it's a multiple of 16) or try training and skip ahead to the next section where you can use a pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "17671bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-d84b564e8e9ab2c6\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-d84b564e8e9ab2c6\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3f7d96ab",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "3f7d96ab",
    "outputId": "6ba0e227-d59d-4c74-fbdf-60cfef8b5f72",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 327.91846\n",
      "Epoch 10 301.635\n",
      "Epoch 20 300.02014\n",
      "Epoch 30 306.35687\n",
      "Epoch 40 302.80307\n",
      "Epoch 50 307.7569\n",
      "Epoch 60 306.06592\n",
      "Epoch 70 305.9325\n",
      "Epoch 80 1.7395225\n",
      "Epoch 90 1.6795809\n",
      "Epoch 100 1.637325\n",
      "Epoch 110 1.4939232\n",
      "Epoch 120 0.52145284\n",
      "Epoch 130 0.18813533\n",
      "Epoch 140 0.1163591\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25468/973010848.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_full\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0maec_only_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# Check the validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mvalid_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_bs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_nbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;31m# Logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_25468/3567149815.py\u001b[0m in \u001b[0;36mvalidation_run\u001b[0;34m(model, state, data, batch_size, num_batches)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mperms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux_loss_means\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexec_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maux_loss_means\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/jax/_src/lax/control_flow.py\u001b[0m in \u001b[0;36mscan\u001b[0;34m(f, init, xs, length, reverse, unroll)\u001b[0m\n\u001b[1;32m   1633\u001b[0m                         init_tree, carry_avals)\n\u001b[1;32m   1634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1635\u001b[0;31m   out = scan_p.bind(*consts, *in_flat,\n\u001b[0m\u001b[1;32m   1636\u001b[0m                     \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1637\u001b[0m                     \u001b[0mnum_consts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconsts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_carry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/jax/_src/lax/control_flow.py\u001b[0m in \u001b[0;36mscan_bind\u001b[0;34m(*args, **params)\u001b[0m\n\u001b[1;32m   2210\u001b[0m     \u001b[0m_scan_typecheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mavals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2211\u001b[0m     \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_jaxpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'jaxpr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjaxpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2212\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAxisPrimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscan_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2214\u001b[0m \u001b[0mscan_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAxisPrimitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"scan\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/jax/core.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m   2039\u001b[0m     top_trace = (top_trace if not axis_main or axis_main.level < top_trace.level\n\u001b[1;32m   2040\u001b[0m                  else axis_main.with_cur_sublevel())\n\u001b[0;32m-> 2041\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind_with_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/jax/core.py\u001b[0m in \u001b[0;36mbind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbind_with_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiple_results\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfull_lower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/jax/core.py\u001b[0m in \u001b[0;36mprocess_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/jax/_src/dispatch.py\u001b[0m in \u001b[0;36mapply_primitive\u001b[0;34m(prim, *args, **params)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mapply_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m   \u001b[0;34m\"\"\"Impl rule that compiles and runs a single primitive 'prim' using XLA.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m   compiled_fun = xla_primitive_callable(prim, *unsafe_map(arg_spec, args),\n\u001b[0m\u001b[1;32m     93\u001b[0m                                         **params)\n\u001b[1;32m     94\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mcompiled_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/jax/_src/util.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trace_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_clear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_clear\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/jax/_src/util.py\u001b[0m in \u001b[0;36mcached\u001b[0;34m(_, *args, **kwargs)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlru_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/jax/_src/dispatch.py\u001b[0m in \u001b[0;36mxla_primitive_callable\u001b[0;34m(prim, *arg_specs, **params)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m   compiled = _xla_callable_uncached(lu.wrap_init(prim_fun), device, None,\n\u001b[0m\u001b[1;32m    112\u001b[0m                                     prim.name, donated_invars, *arg_specs)\n\u001b[1;32m    113\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mprim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiple_results\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/jax/_src/dispatch.py\u001b[0m in \u001b[0;36m_xla_callable_uncached\u001b[0;34m(fun, device, backend, name, donated_invars, *arg_specs)\u001b[0m\n\u001b[1;32m    167\u001b[0m def _xla_callable_uncached(fun: lu.WrappedFun, device, backend, name,\n\u001b[1;32m    168\u001b[0m                            donated_invars, *arg_specs):\n\u001b[0;32m--> 169\u001b[0;31m   return lower_xla_callable(fun, device, backend, name, donated_invars,\n\u001b[0m\u001b[1;32m    170\u001b[0m                             *arg_specs).compile().unsafe_call\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/jax/_src/dispatch.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    526\u001b[0m             **self.compile_args)\n\u001b[1;32m    527\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m         self._executable = XlaCompiledComputation.from_xla_computation(\n\u001b[0m\u001b[1;32m    529\u001b[0m             self.name, self._hlo, **self.compile_args)\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/jax/_src/dispatch.py\u001b[0m in \u001b[0;36mfrom_xla_computation\u001b[0;34m(name, xla_computation, nreps, device, backend, tuple_args, in_avals, out_avals, kept_var_idx)\u001b[0m\n\u001b[1;32m    612\u001b[0m     with log_elapsed_time(f\"Finished XLA compilation of {name} \"\n\u001b[1;32m    613\u001b[0m                           \"in {elapsed_time} sec\"):\n\u001b[0;32m--> 614\u001b[0;31m       \u001b[0mcompiled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompile_or_get_cached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxla_computation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m     buffer_counts = (None if len(out_avals) == 1 else\n\u001b[1;32m    616\u001b[0m                      [aval_to_num_buffers(aval) for aval in out_avals])\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/jax/_src/dispatch.py\u001b[0m in \u001b[0;36mcompile_or_get_cached\u001b[0;34m(backend, computation, compile_options)\u001b[0m\n\u001b[1;32m    581\u001b[0m               else computation.as_hlo_text())\n\u001b[1;32m    582\u001b[0m     \u001b[0m_dump_ir_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mir_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mbackend_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomputation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/jax/_src/profiler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mTraceAnnotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdecorator_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/jax/_src/dispatch.py\u001b[0m in \u001b[0;36mbackend_compile\u001b[0;34m(backend, built_c, options)\u001b[0m\n\u001b[1;32m    535\u001b[0m   \u001b[0;31m# we use a separate function call to ensure that XLA compilation appears\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m   \u001b[0;31m# separately in Python profiling results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuilt_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;31m# TODO(phawkins): update users.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Train housekeeping\n",
    "train_size = train_len_func()\n",
    "n_batches = train_size // batch_size\n",
    "\n",
    "#Validation housekeeping\n",
    "valid_size = valid_len_func()\n",
    "valid_bs = 512\n",
    "valid_nbatches = valid_size // valid_bs\n",
    "\n",
    "# General run things\n",
    "aec_only_epochs = 75\n",
    "full_epochs = 2500\n",
    "train_writer = tensorboard.SummaryWriter('train')\n",
    "valid_writer = tensorboard.SummaryWriter('valid')\n",
    "log_rate = 10\n",
    "loss_names= ['L'+str(i) for i in range(1, 7)]\n",
    "key = rnd.PRNGKey(0)\n",
    "\n",
    "for i in range(full_epochs):\n",
    "    # Run the training epoch\n",
    "    key, use_key = rnd.split(key, 2)\n",
    "    perm = rnd.permutation(use_key, train_size)[:batch_size*n_batches].reshape(n_batches, batch_size)\n",
    "    state, train_loss = train_epoch(model, state, train_dataset, perm, n_batches, eval_full=i>aec_only_epochs)\n",
    "    # Check the validation set\n",
    "    valid_losses = validation_run(model, state, valid_dataset, valid_bs, valid_nbatches)\n",
    "    # Logging\n",
    "    for j, loss in enumerate(train_loss):\n",
    "        train_writer.scalar(loss_names[j], loss, i)\n",
    "        valid_writer.scalar(loss_names[j], valid_losses[j], i)\n",
    "    train_writer.scalar('Total loss', jnp.sum(jnp.array(train_loss)), i)\n",
    "    valid_writer.scalar('Total loss', jnp.sum(jnp.array(valid_losses)), i)  \n",
    "    if i % log_rate == 0:\n",
    "        print('Epoch', i, 'Total validation loss:', jnp.sum(jnp.array(valid_losses)))\n",
    "        checkpoints.save_checkpoint('checkpoints', state, i, keep=3, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714deaf7",
   "metadata": {},
   "source": [
    "## Experimenting with Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b198a8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.72 s Â± 15.7 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "## Uncomment this to use pretrained model\n",
    "# n = 128\n",
    "# model = DeepGreen(n)\n",
    "\n",
    "## Uncomment this to use trained model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3621c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DeepGreen_rough.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
