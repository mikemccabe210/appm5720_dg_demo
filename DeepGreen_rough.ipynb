{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28dbb055",
   "metadata": {
    "id": "28dbb055"
   },
   "source": [
    "# APPM 5720 DeepGreen Example Notebook\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mikemccabe210/appm5720_dg_demo/blob/main/DeepGreen_rough.ipynb)\n",
    "\n",
    "#### Paper: DeepGreen: deep learning of Green’s functions for nonlinear boundary value problems\n",
    "#### Paper by: Craig R. Gin, Daniel E. Shea, Steven L. Brunton, and J. Nathan Kutz\n",
    "#### Notebook by: Rey Koki and Mike McCabe\n",
    "\n",
    "\n",
    "\n",
    "This notebook walks through the nonlinear Poisson problem from _DeepGreen_. Several steps are slightly simplified from the original code, which can be found here: https://github.com/sheadan/DeepGreen, since we're only implementing one example and do not need the fully general code. We also make a few small departures for efficiency/speed purposes. These will be pointed out when they come up.\n",
    "\n",
    "## Nonlinear Poisson\n",
    "\n",
    "\n",
    "\n",
    "Put the problem description here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "UGCmpVjYxrnv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UGCmpVjYxrnv",
    "outputId": "dde0fa91-f21c-43b5-885d-9a33fa488e84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optax\n",
      "  Downloading optax-0.1.1-py3-none-any.whl (136 kB)\n",
      "\u001b[?25l\r",
      "\u001b[K     |██▍                             | 10 kB 20.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████▉                           | 20 kB 10.2 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▏                        | 30 kB 8.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▋                      | 40 kB 8.2 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 51 kB 4.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▍                 | 61 kB 5.0 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▉               | 71 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▎            | 81 kB 5.7 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▋          | 92 kB 6.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 102 kB 5.0 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▌     | 112 kB 5.0 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▉   | 122 kB 5.0 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▎| 133 kB 5.0 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 136 kB 5.0 MB/s \n",
      "\u001b[?25hCollecting flax\n",
      "  Downloading flax-0.4.0-py3-none-any.whl (176 kB)\n",
      "\u001b[K     |████████████████████████████████| 176 kB 43.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.7/dist-packages (from optax) (0.1.71+cuda111)\n",
      "Requirement already satisfied: jax>=0.1.55 in /usr/local/lib/python3.7/dist-packages (from optax) (0.2.25)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from optax) (1.21.5)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0 in /usr/local/lib/python3.7/dist-packages (from optax) (3.10.0.2)\n",
      "Collecting chex>=0.0.4\n",
      "  Downloading chex-0.1.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 3.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from optax) (1.0.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.7.1->optax) (1.15.0)\n",
      "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax) (0.1.6)\n",
      "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax) (0.11.2)\n",
      "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->optax) (1.4.1)\n",
      "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->optax) (3.3.0)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from jaxlib>=0.1.37->optax) (2.0)\n",
      "Requirement already satisfied: msgpack in /usr/local/lib/python3.7/dist-packages (from flax) (1.0.3)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from flax) (3.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (2.8.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (3.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (1.3.2)\n",
      "Installing collected packages: chex, optax, flax\n",
      "Successfully installed chex-0.1.0 flax-0.4.0 optax-0.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install optax flax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "083b497f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "id": "083b497f",
    "outputId": "629f0ad8-ab58-4357-9d5b-49d21aae1020"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used cpu\n"
     ]
    }
   ],
   "source": [
    "# Imports!\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.random as rnd\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "import flax.linen as nn\n",
    "import functools\n",
    "from flax.training import train_state\n",
    "from flax.metrics import tensorboard\n",
    "from random import shuffle\n",
    "from typing import Sequence, Callable, Any, Optional, Dict\n",
    "from jax.lib import xla_bridge\n",
    "print('Device used', xla_bridge.get_backend().platform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcb43d8",
   "metadata": {
    "id": "bfcb43d8"
   },
   "source": [
    "## Defining the Neural Network\n",
    "\n",
    "Here we define the neural network. Here, we use the Flax library built on top of JAX. JAX is an automatic differentiation and linear algebra acceleration library developed by Google. The API is intended to mimic numpy, though it has the added capability for functional transformations like computing gradients, automatically vectorizing code, or just-in-time (JIT) compiling it down to XLA code.\n",
    "\n",
    "Flax tends to have quite a bit of complexity hidden behind the scenes which makes it a bit harder to use than comparable libraries like PyTorch. Looking through the code below, it might seem like some things are being instantiated every time the model is called, but in practice, these objects are traced when they are instantiated and the actual object being behaves slightly differently. \n",
    "\n",
    "The model itself consists of two sets of encoders/decoders with the linear operator acting as a coupling mechanism in the encoding space. We start off by defining the Encoder and Decoder templates:\n",
    "\n",
    "__We didn't directly parameterize the encoder/decoders in DeepGreen for this demo, so to adjust the layers/depth/activations you'll have to do it directly (or adjust the code to pass parameters to the inner modules. If you adjust the layer count, you also need to adjust the downsampling factor in GreenNet to use custom resolutions (values of n).__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06c81cc",
   "metadata": {
    "id": "d06c81cc"
   },
   "outputs": [],
   "source": [
    "class Conv2DEncoder(nn.Module):\n",
    "    # This is a DataClass, so these implicitly define init parameters\n",
    "    num_filters: Sequence[int] = (8, 16, 32, 64)\n",
    "    conv_window: Sequence[int] = (4, 4)\n",
    "    conv_strides: int = (1,1)\n",
    "    conv_padding: str = 'SAME'\n",
    "    pool_window: Sequence[int] = (2, 2)\n",
    "    pool_strides: int = (2,2)\n",
    "    pool_padding: str = 'VALID'\n",
    "    act_fn: Callable = nn.relu\n",
    "    add_init_fin: bool = True\n",
    "        \n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        inputs = x[:] # Save copy of inputs for residual        \n",
    "        for i, filters in enumerate(self.num_filters):\n",
    "            if i > 0:\n",
    "                x = nn.avg_pool(x, window_shape=self.pool_window,\n",
    "                                strides=self.pool_strides,\n",
    "                               padding=self.pool_padding)\n",
    "            x = nn.Conv(features=filters, kernel_size=self.conv_window,\n",
    "                       strides=self.conv_strides, padding=self.conv_padding)(x)\n",
    "            x = self.act_fn(x)\n",
    "            # If residual included, add projected inputs\n",
    "        if self.add_init_fin:\n",
    "            inputs = nn.Conv(features=self.num_filters[-1], \n",
    "                        kernel_size=(2**(len(self.num_filters)-1),)*2,\n",
    "                         strides=(2**(len(self.num_filters)-1),)*2,\n",
    "                        padding='VALID')(inputs)\n",
    "\n",
    "            x += inputs\n",
    "        return x.reshape(x.shape[0], -1)\n",
    "                \n",
    "    \n",
    "class Conv2DDecoder(nn.Module):\n",
    "    init_size: Sequence[int] = (16, 16, 64)\n",
    "    output_size: Sequence[int] = (-1, 128, 128)\n",
    "    num_filters: Sequence[int] = (32, 16, 8)\n",
    "    conv_window: Sequence[int] = (4, 4)\n",
    "    conv_strides:int = (2,2)\n",
    "    conv_padding: str = 'SAME'\n",
    "    act_fn: Callable = nn.relu\n",
    "    add_init_fin: bool = True\n",
    "        \n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = x.reshape(-1, *self.init_size)\n",
    "        inputs = x[:]\n",
    "        for filters in self.num_filters:\n",
    "            x = nn.ConvTranspose(features=filters, kernel_size=self.conv_window,\n",
    "                                 strides=self.conv_strides, padding=self.conv_padding)(x)\n",
    "            x = self.act_fn(x)\n",
    "        # Do one last small convolution\n",
    "        x = nn.ConvTranspose(features=1,\n",
    "                             kernel_size=self.conv_window,\n",
    "                            strides=(1,1),\n",
    "                            padding=self.conv_padding)(x).squeeze(-1)\n",
    "        \n",
    "        # Note this a departure from the actual paper code\n",
    "        # which just reshapes the encoder space to add. Since\n",
    "        # that makes no sense (it's like trying to add a smaller color\n",
    "        # image to a larger greyscale image by shifting the RGB values to different\n",
    "        # pixels to make the shapes line up), we've swapped to standard upsampling\n",
    "        if self.add_init_fin:\n",
    "            inputs = nn.Conv(features=1, kernel_size=(1, 1))(inputs).squeeze(-1)\n",
    "            inputs = jax.image.resize(inputs, shape=(inputs.shape[0], *self.output_size[1:]), method='linear')\n",
    "            x += inputs\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634377d0",
   "metadata": {
    "id": "634377d0"
   },
   "source": [
    "Once the encoders and decoders are built, the full model just connects the encoder/decoder pairs through a few linear projections and the linear operator. The sequential linear operations are a little unconventional as these are essentially a single low-rank linear operator though with the coupling $Lv=f$/$L^{-1}f=v$ promoted by the loss function.\n",
    "\n",
    "Note that we return all values included in loss functions. In applications, one would likely only be using the trained model to infer $u$ from $f$ and as such would not require all outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50eb2a30",
   "metadata": {
    "id": "50eb2a30"
   },
   "outputs": [],
   "source": [
    "class GreenNet(nn.Module):\n",
    "    # Note, since we're only doing the nonlinear Poisson example,\n",
    "    # we removed some of the parameterization here to simplify things\n",
    "    n: int = 128\n",
    "    units_latent: int = 200    \n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, inputs):\n",
    "        u, F = inputs\n",
    "        \n",
    "        # Let's define our modules. Since we reuse them, it probably would have\n",
    "        # made more sense to not use nn.compact and just use a setup function\n",
    "        # but it is too late now. This is getting traced anyway,\n",
    "        # so it doesn't actually matter apart from looking a bit clunky.\n",
    "        u_encoder = Conv2DEncoder()\n",
    "        u_decoder = Conv2DDecoder(output_size=(-1, self.n, self.n), init_size=(self.n//8, self.n//8, 64))\n",
    "        v_reducer = nn.Dense(self.units_latent)\n",
    "        v_expander = nn.Dense(self.n**2)\n",
    "        \n",
    "        F_encoder = Conv2DEncoder()\n",
    "        F_decoder = Conv2DDecoder(output_size=(-1, self.n, self.n), init_size=(self.n//8, self.n//8, 64))\n",
    "        f_reducer = nn.Dense(self.units_latent)\n",
    "        f_expander = nn.Dense(self.n**2)\n",
    "        \n",
    "        operator = self.param('Operator', init_fn=lambda key: jnp.eye(self.units_latent)*1.)\n",
    "\n",
    "        # Autoencode u\n",
    "        u_encoded = u_encoder(u)\n",
    "        # I guess this avoids doing a large dense matrix inverse\n",
    "        v = v_reducer(u_encoded)\n",
    "        v_exp = v_expander(v)\n",
    "        u_decoded = u_decoder(v_exp)\n",
    "        \n",
    "        # Autoencode F\n",
    "        F_encoded = F_encoder(F)\n",
    "        f = f_reducer(F_encoded)\n",
    "        f_exp = f_expander(f)\n",
    "        F_decoded = F_decoder(f_exp)  \n",
    "        \n",
    "        # L things - seems kind of wasteful, but L is small\n",
    "        L_upper = jnp.triu(operator)\n",
    "        L = .5*(L_upper+L_upper.T)\n",
    "        \n",
    "        # Forward model\n",
    "        Lv = jax.lax.dot_general(v, L,\n",
    "                                 (((v.ndim - 1,), (0,)), ((), ())),)\n",
    "        Lv_exp = f_expander(Lv)\n",
    "        Lv_decoded = F_decoder(Lv_exp)\n",
    "        \n",
    "        # Inverse model\n",
    "        Linvf = jnp.linalg.solve(jnp.expand_dims(L, 0), f)\n",
    "        Linvf_exp = f_expander(Linvf)\n",
    "        Linvf_decoded = F_decoder(Linvf_exp)\n",
    "        \n",
    "        return u_decoded, F_decoded, Lv_decoded, Linvf_decoded, f, v, Lv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dff1b0",
   "metadata": {
    "id": "55dff1b0"
   },
   "source": [
    "## Building the data set\n",
    "\n",
    "We handle data a bit differently from the paper to avoid forcing everyone to download several GB of data. The paper generated data by sampling forcing functions and using an external solver to generate solutions. This is time consuming and doesn't actually compute the exact loss. We instead use the Method of Manufactured Solutions (MMS) so that we can generate solutions and forcings in real time.\n",
    "\n",
    "As opposed to computing true solutions for given forcings, in MMS, you sample solutions and compute the forcing by applying the differential operator to the solution. While this doesn't always result in realistic problems and generally requires smooth solutions, it is much, much faster and more accurate than generating data from numerical solvers. The downside is that using their forcings as solutions breaks boundary conditions which isn't ideal given the proposal is to learn a Green's function in the encoder space, so we changed some of the functions up to ensure homogeneous BCs. \n",
    "\n",
    "This data API here is a little weird - the original version was too slow for demo purposes, so the final version is a mix between the original version (which used a more standard data API) and a JIT-friendly data API. The test/train split components are the main victims here as they ultimately got hard-coded with some unnecessary storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd143ed1",
   "metadata": {
    "id": "bd143ed1"
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "def nlp_operator(u):\n",
    "    \"\"\" Transforms function by applying the nonlinear Poisson operator:\n",
    "      \n",
    "        Pu = -\\nabla \\dot ((1+u^2)\\nabla u)\n",
    "    \"\"\"\n",
    "    flux = lambda x: (1+u(x)**2)*(jax.grad(u)(x))\n",
    "    return lambda x: (-jax.jacfwd(flux)(x)*jnp.eye(2)).sum()\n",
    "    \n",
    "def jax_collate(batch):\n",
    "    if isinstance(batch[0], jnp.DeviceArray):\n",
    "        return jnp.stack(batch)\n",
    "    elif isinstance(batch[0], (tuple,list)):\n",
    "        transposed = zip(*batch)\n",
    "        return [jax_collate(samples) for samples in transposed]\n",
    "    else:\n",
    "        return jnp.array(batch)\n",
    "    \n",
    "def NLP_Dataset_Sampler(n=128, batch_size=64, cubic=False, train=True, valid=False, test=False):\n",
    "    \"\"\" Factory for building data samplers for training.\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    n ~ int: Number of grid points in the x and y directions\n",
    "    batch size ~ int: Examples per batch.\n",
    "    cubic ~ bool: Indicator whether to sample from the cubic space\n",
    "    train ~ bool: Indicator whether to use the train indices\n",
    "    valid ~ bool: Indicator whether to use the validation indices\n",
    "    test ~ bool: Indicator whether to use the (non-cubic) test indices\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    sampler ~ Callable: takes in indices and returns data\n",
    "    len_func ~ Callable: zero parameter function that returns the dataset size.\n",
    "    \"\"\"\n",
    "    ##### u, F Builder Functions ######\n",
    "    def gamma(k):\n",
    "        return .01 +.28*k/3\n",
    "              \n",
    "    def build_gaussian(params):\n",
    "        # Just multiplied by sin to get BCs\n",
    "        a, bx, by, c = params\n",
    "        u = lambda x: a*jnp.exp((-(x[0]-bx)**2 - (x[1]-by)**2)/(2*c**2))*jnp.sin(x[0])*jnp.sin(x[1])\n",
    "        F = nlp_operator(u)\n",
    "        Um, Fm = jax.vmap(u), jax.vmap(F)\n",
    "        return Um(coords), Fm(coords)\n",
    "    \n",
    "    def build_cosine(params):\n",
    "        # Actually sines\n",
    "        alpha, betax, betay, _ = params \n",
    "        u = lambda x: alpha*jnp.sin(betax*x[0])*jnp.sin(betay*x[1])\n",
    "        F = nlp_operator(u)\n",
    "        Um, Fm = jax.vmap(u), jax.vmap(F)\n",
    "        return Um(coords), Fm(coords)\n",
    "    \n",
    "    \n",
    "    def build_cubic1(params):\n",
    "        # Moved 0s\n",
    "        kx, ky, _, _ = params\n",
    "        u = lambda x:kx*(x[0]-jnp.pi)*(x[0]-2*jnp.pi)*x[0] \\\n",
    "                        + ky*(x[1]-jnp.pi)*(x[1]-2*jnp.pi)*x[1]\n",
    "        F = nlp_operator(u)\n",
    "        Um, Fm = jax.vmap(u), jax.vmap(F)\n",
    "        return Um(coords), Fm(coords)\n",
    "    \n",
    "    def build_cubic2(params):\n",
    "        # Moved 0s and removed psi\n",
    "        kx, ky, zetax, zetay = params\n",
    "        u = lambda x: kx*(x[0]-jnp.pi)*(x[0]-2*jnp.pi)*x[0] + ky*(x[1]-jnp.pi)*(x[1]-2*jnp.pi)*x[1] \\\n",
    "                        + zetax*(x[0]-2*jnp.pi)*x[0] + zetay*(x[1]-2*jnp.pi)*x[1]\n",
    "        F = nlp_operator(u)\n",
    "        Um, Fm = jax.vmap(u), jax.vmap(F)\n",
    "        return Um(coords), Fm(coords)\n",
    "\n",
    "    ##### Actual Sampling functions #####\n",
    "    def get_len():\n",
    "        return len(data)\n",
    "    \n",
    "    def get_item(idx):\n",
    "        sub = data[idx]\n",
    "        func_build, params = sub[0], sub[1:]\n",
    "        u, F = jax.lax.switch(func_build.astype(int), [build_gaussian, build_cosine,\n",
    "                                                      build_cubic1, build_cubic2], params) \n",
    "        return u.reshape(n, n, 1), F.reshape(n, n, 1)\n",
    "    \n",
    "    sample = jax.vmap(get_item)\n",
    "    \n",
    "    # Build shared state for all inner functions\n",
    "    if not cubic:\n",
    "        # Set up Gaussians\n",
    "        a_range = jnp.arange(-25, 26., 5)\n",
    "        b_range = jnp.arange(jnp.pi/3, 5*jnp.pi/3+.01, jnp.pi/3)\n",
    "        c_range = jnp.arange(.1, 5, .2)\n",
    "        gauss_params = [(0.,)+ p for p in product(a_range, b_range, b_range, c_range)]\n",
    "\n",
    "        alpha_range = jnp.arange(1, 10.1, .1)\n",
    "        beta_range = jnp.arange(1, 5.1, .5)\n",
    "        cosine_params = [(1.,)+ p+(0,) \n",
    "                         for p in product(alpha_range, beta_range, beta_range)]\n",
    "\n",
    "        total_params = gauss_params + cosine_params\n",
    "        shuffle(total_params)\n",
    "\n",
    "        # Hard coding the values from the paper even though it's not the same\n",
    "        if train:\n",
    "            data = total_params[:9806]\n",
    "        elif valid:\n",
    "            data = total_params[9806:9806+2452]\n",
    "        else:\n",
    "            data = total_params[9806+2452:]\n",
    "\n",
    "    else:\n",
    "        k = gamma(jnp.array([0, 1, 2, 3]))\n",
    "#         psi = jnp.arange(-5, 6., 1)\n",
    "        zeta = jnp.arange(.01, .26, .6)\n",
    "        cubic1_params = [(2.,) + p+(0,0)\n",
    "                       for p in product(k, k)]\n",
    "        cubic2_params = [(3.,) + p\n",
    "                       for p in product(k, k, zeta, zeta)]\n",
    "        data = cubic1_params + cubic2_params\n",
    "\n",
    "    data = jnp.array(data)\n",
    "    # Build the mesh once and reuse\n",
    "    xx, yy = jnp.meshgrid(jnp.linspace(0, 2*jnp.pi, n), jnp.linspace(0, 2*jnp.pi, n))\n",
    "    coords = jnp.stack([xx, yy], -1).reshape(-1, 2)\n",
    "    \n",
    "    return jax.jit(sample), get_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c717765",
   "metadata": {
    "id": "2c717765"
   },
   "source": [
    "## Setting up the run\n",
    "\n",
    "Some of the components of our neural network are initialized lazily, so we need to pass some example data through to finish configuring things. The actual content of that data doesn't matter - just the shapes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c692c17a",
   "metadata": {
    "id": "c692c17a",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Model run parameters\n",
    "aec_only_epochs = 75\n",
    "full_epochs = 2500\n",
    "best_model_epochs = 2500\n",
    "batch_size = 64\n",
    "n=128\n",
    "\n",
    "# Content doesn't matter so we're just chosing a convenient shape\n",
    "init_vals = jnp.array(np.random.uniform(size=(10, n, n, 1)))\n",
    "\n",
    "# JAX's random is kind of a pain, but it makes more sense when you're doing distributed training\n",
    "# which we are not doing here. \n",
    "key = rnd.PRNGKey(0)\n",
    "key, use_key = rnd.split(key, 2)\n",
    "\n",
    "model = GreenNet(n=n)\n",
    "params = model.init(use_key, (init_vals, init_vals))\n",
    "\n",
    "# JAX is a functional framework, but Deep Learning has historically used mostly object oriented libraries.\n",
    "# TrainState is a helper for organizing the model parameters and state so the training loop can be written \n",
    "# more like OOP code.\n",
    "\n",
    "# We're using the AdamW optimizer as the paper uses Adam with weight decay. \n",
    "\n",
    "state = train_state.TrainState.create(apply_fn=model.apply,\n",
    "                                     params = params['params'],\n",
    "                                     tx=optax.adamw(learning_rate=1e-3, weight_decay=1e-6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a538548",
   "metadata": {
    "id": "7a538548"
   },
   "source": [
    "Now we'll define the training loops. The paper uses multiple parallel runs and takes the best performing models. This is going to be running on Colab so you are not going to have the hardware for that. Instead, we're just going to train a single model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f560cf10",
   "metadata": {
    "id": "f560cf10"
   },
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def update_params(state, grads):\n",
    "    return state.apply_gradients(grads=grads)\n",
    "\n",
    "        \n",
    "@jax.jit\n",
    "def compute_losses(u, F, u_decoded, F_decoded, Lv_decoded, Linvf_decoded, f, v, Lv, eps=1e-5):\n",
    "    \"\"\" Computes the 6 Normalized MSEs from the paper.\n",
    "    \n",
    "    Note: the use of means instead of sums in computing squared norms is from the paper\n",
    "    code.\n",
    "    \"\"\"\n",
    "    # Loss 1 - Reconstruction u\n",
    "    loss1 = (((u_decoded - u)**2).mean((1, 2)) / ((u**2).mean((1,2))+eps)).sum()\n",
    "    # Loss 2 - Reconstruction f \n",
    "    loss2 = (((F_decoded - F)**2).mean((1, 2)) / ((F**2).mean((1,2))+eps)).sum()\n",
    "    # Loss 3 - Forward in encoded space - don't love the gradient dynamics of dividing here\n",
    "    loss3 = (((Lv - f)**2).mean(-1) / ((f**2).mean(-1)+eps)).sum()\n",
    "    # Loss 4 - \"Superposition\" loss - seems like it would just change the relative weight of loss 3 \n",
    "    # in a weird non-convex way and penalize the magnitude of the encoded vectors. Doesn't seem like \n",
    "    # a great idea, but it is in the paper\n",
    "    loss4 = 0.\n",
    "    # Loss 5 - Forward operator loss\n",
    "    loss5 = (((Lv_decoded - F)**2).mean((1, 2)) / ((F**2).mean((1,2))+eps)).sum()\n",
    "    # Loss 6 - Backwards operator loss\n",
    "    loss6 = (((Linvf_decoded - u)**2).mean((1, 2)) / ((u**2).mean((1,2))+eps)).sum()\n",
    "    return loss1, loss2, loss3, loss4, loss5, loss6\n",
    "\n",
    "@functools.partial(jax.jit, static_argnums=(0, 2, 4, 5))\n",
    "def train_epoch(model, state, data, perms, num_batches, eval_full=True):\n",
    "    # JIT is touchy around conditionals (the trace notes the first path), so this just says compile\n",
    "    #  again if the conditional changes. \n",
    "    @functools.partial(jax.jit)\n",
    "    def grad_step(state, perm):\n",
    "        def loss_fn(params):\n",
    "            # Run model\n",
    "            u_decoded, F_decoded, Lv_decoded, Linvf_decoded, f, v, Lv = model.apply({'params':params}, batch)\n",
    "            u, F = batch\n",
    "            u, F = u.squeeze(-1), F.squeeze(-1)\n",
    "            loss1, loss2, loss3, loss4, loss5, loss6 = compute_losses(u, F, u_decoded, F_decoded, \n",
    "                                                                      Lv_decoded, Linvf_decoded, f, v, Lv)\n",
    "            # We're keeping all the losses for logging, but the total loss is only the reconstruction\n",
    "            # losses at the beginning of training\n",
    "            if eval_full:\n",
    "                return loss1+loss2+loss3+loss4+loss5+loss6, (loss1, loss2, loss3, loss4, loss5, loss6)\n",
    "            else:\n",
    "                return loss1+loss2, (loss1, loss2, loss3, loss4, loss5, loss6)\n",
    "        \n",
    "        batch = data(perm)\n",
    "        grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "        (train_loss, aux_losses), grads = grad_fn(state.params)\n",
    "        state = update_params(state, grads)\n",
    "        return state, aux_losses\n",
    "\n",
    "    # Run actual code - Carries and updates state every batch\n",
    "    # returns final state and accumulated outputs (losses)\n",
    "    state, aux_loss_means = jax.lax.scan(grad_step, state, perms)\n",
    "    return state, [jnp.mean(l) for l in aux_loss_means]   \n",
    "\n",
    "def validation_run(model, state, data):\n",
    "    # Bad design choice led to duplicate code here.\n",
    "    @functools.partial(jax.jit)\n",
    "    def exec_step(state, perm):\n",
    "        def loss_fn(params):\n",
    "            # Run model\n",
    "            u_decoded, F_decoded, Lv_decoded, Linvf_decoded, f, v, Lv = model.apply({'params':params}, batch)\n",
    "            u, F = batch\n",
    "            u, F = u.squeeze(-1), F.squeeze(-1)\n",
    "            loss1, loss2, loss3, loss4, loss5, loss6 = compute_losses(u, F, u_decoded, F_decoded, \n",
    "                                                                      Lv_decoded, Linvf_decoded, f, v, Lv)\n",
    "            # We're keeping all the losses for logging, but the total loss is only the reconstruction\n",
    "            # losses at the beginning of training\n",
    "            return loss1+loss2+loss3+loss4+loss5+loss6, (loss1, loss2, loss3, loss4, loss5, loss6)\n",
    "        batch = data(perm)\n",
    "        (train_loss, aux_losses), grads = grad_fn(state.params)\n",
    "        state = update_params(state, grads)\n",
    "        return state, aux_losses\n",
    "        \n",
    "    \n",
    "#     return loss, aug_losses, worst_ex, best_ex\n",
    "    \n",
    "# Load up on datasets - the len funcs instead of objects were just a mistake\n",
    "train_dataset, train_len_func = NLP_Dataset_Sampler(n=n, batch_size=batch_size)\n",
    "valid_dataset, valid_len_func = NLP_Dataset_Sampler(n=n, batch_size=batch_size, train=False, test=True)\n",
    "test_dataset, test_len_func = NLP_Dataset_Sampler(n=n, batch_size=batch_size, train=False, test=True)\n",
    "cubic_test_dataset, cubic_len_func = NLP_Dataset_Sampler(n=n, batch_size=batch_size, cubic=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7d96ab",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "3f7d96ab",
    "outputId": "6ba0e227-d59d-4c74-fbdf-60cfef8b5f72",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [DeviceArray(44.26295, dtype=float32), DeviceArray(513.84595, dtype=float32), DeviceArray(65.05397, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(325.9851, dtype=float32), DeviceArray(2.4416893e+08, dtype=float32)]\n",
      "1 [DeviceArray(8.394817, dtype=float32), DeviceArray(110.09407, dtype=float32), DeviceArray(62.235832, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(89.24215, dtype=float32), DeviceArray(36469760., dtype=float32)]\n",
      "2 [DeviceArray(2.2918518, dtype=float32), DeviceArray(64.45187, dtype=float32), DeviceArray(59.196648, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(62.93146, dtype=float32), DeviceArray(4152619.5, dtype=float32)]\n",
      "3 [DeviceArray(2.346943, dtype=float32), DeviceArray(62.963543, dtype=float32), DeviceArray(56.586636, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(62.34431, dtype=float32), DeviceArray(1185976.5, dtype=float32)]\n",
      "4 [DeviceArray(2.233121, dtype=float32), DeviceArray(62.473934, dtype=float32), DeviceArray(53.263935, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(62.081207, dtype=float32), DeviceArray(644840.2, dtype=float32)]\n",
      "5 [DeviceArray(2.7218087, dtype=float32), DeviceArray(62.248653, dtype=float32), DeviceArray(48.68203, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(61.945053, dtype=float32), DeviceArray(477320.94, dtype=float32)]\n",
      "6 [DeviceArray(3.6236181, dtype=float32), DeviceArray(62.07531, dtype=float32), DeviceArray(42.93542, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(61.86514, dtype=float32), DeviceArray(416201.16, dtype=float32)]\n",
      "7 [DeviceArray(4.3453407, dtype=float32), DeviceArray(61.93431, dtype=float32), DeviceArray(36.770943, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(61.75069, dtype=float32), DeviceArray(375356.75, dtype=float32)]\n",
      "8 [DeviceArray(4.373227, dtype=float32), DeviceArray(61.856983, dtype=float32), DeviceArray(32.27041, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(61.667202, dtype=float32), DeviceArray(370681.94, dtype=float32)]\n",
      "9 [DeviceArray(4.654533, dtype=float32), DeviceArray(61.819687, dtype=float32), DeviceArray(29.03198, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(61.635838, dtype=float32), DeviceArray(302966.66, dtype=float32)]\n",
      "10 [DeviceArray(4.216803, dtype=float32), DeviceArray(61.745174, dtype=float32), DeviceArray(25.63227, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(61.572388, dtype=float32), DeviceArray(235960.22, dtype=float32)]\n",
      "11 [DeviceArray(3.712489, dtype=float32), DeviceArray(61.698257, dtype=float32), DeviceArray(23.430387, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(61.53545, dtype=float32), DeviceArray(416579.3, dtype=float32)]\n",
      "12 [DeviceArray(3.8088288, dtype=float32), DeviceArray(61.647083, dtype=float32), DeviceArray(23.493315, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(61.51105, dtype=float32), DeviceArray(406510.75, dtype=float32)]\n",
      "13 [DeviceArray(3.3929205, dtype=float32), DeviceArray(61.58258, dtype=float32), DeviceArray(18.213873, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(61.458042, dtype=float32), DeviceArray(104456.51, dtype=float32)]\n",
      "14 [DeviceArray(3.2011967, dtype=float32), DeviceArray(61.560574, dtype=float32), DeviceArray(16.688726, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(61.42958, dtype=float32), DeviceArray(78119.71, dtype=float32)]\n",
      "15 [DeviceArray(3.3283613, dtype=float32), DeviceArray(61.541622, dtype=float32), DeviceArray(19.89651, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(61.42517, dtype=float32), DeviceArray(182156.86, dtype=float32)]\n",
      "16 [DeviceArray(2.844427, dtype=float32), DeviceArray(61.51568, dtype=float32), DeviceArray(17.58883, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(61.41059, dtype=float32), DeviceArray(125516.38, dtype=float32)]\n",
      "17 [DeviceArray(2.7089417, dtype=float32), DeviceArray(61.523438, dtype=float32), DeviceArray(18.852894, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(61.41539, dtype=float32), DeviceArray(162759.72, dtype=float32)]\n",
      "18 [DeviceArray(2.6561499, dtype=float32), DeviceArray(61.449852, dtype=float32), DeviceArray(15.634683, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(61.355328, dtype=float32), DeviceArray(81396.85, dtype=float32)]\n",
      "19 [DeviceArray(2.643368, dtype=float32), DeviceArray(61.44589, dtype=float32), DeviceArray(16.43726, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(61.345074, dtype=float32), DeviceArray(88806.47, dtype=float32)]\n",
      "20 [DeviceArray(2.333797, dtype=float32), DeviceArray(61.478256, dtype=float32), DeviceArray(22.988716, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(61.369167, dtype=float32), DeviceArray(365795.84, dtype=float32)]\n",
      "21 [DeviceArray(2.1556396, dtype=float32), DeviceArray(61.47736, dtype=float32), DeviceArray(24.003664, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(61.37333, dtype=float32), DeviceArray(410396.88, dtype=float32)]\n",
      "22 [DeviceArray(2.4239306, dtype=float32), DeviceArray(61.44294, dtype=float32), DeviceArray(24.705309, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(61.360424, dtype=float32), DeviceArray(299431.3, dtype=float32)]\n",
      "23 [DeviceArray(2.6359904, dtype=float32), DeviceArray(61.425182, dtype=float32), DeviceArray(20.711924, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(61.37079, dtype=float32), DeviceArray(215737.88, dtype=float32)]\n",
      "24 [DeviceArray(1.8805335, dtype=float32), DeviceArray(61.375443, dtype=float32), DeviceArray(18.098808, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(61.305225, dtype=float32), DeviceArray(53340.254, dtype=float32)]\n",
      "25 [DeviceArray(2.9187021, dtype=float32), DeviceArray(61.356453, dtype=float32), DeviceArray(20.275902, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(61.29207, dtype=float32), DeviceArray(156589.94, dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "from jax.config import config\n",
    "# config.update(\"jax_debug_nans\", True)\n",
    "train_size = train_len_func()\n",
    "n_batches = train_size // batch_size\n",
    "key = rnd.PRNGKey(0)\n",
    "\n",
    "for i in range(full_epochs):\n",
    "    # Batching hack\n",
    "    key, use_key = rnd.split(key, 2)\n",
    "    perm = rnd.permutation(use_key, train_size)[:batch_size*n_batches].reshape(n_batches, batch_size)\n",
    "    state, train_loss = train_epoch(model, state, train_dataset, perm, n_batches, eval_full=i<aec_only_epochs)\n",
    "    print(i, train_loss)\n",
    "#     _, test_loss = validation_run(state, valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a171a2ca",
   "metadata": {
    "id": "a171a2ca"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DeepGreen_rough.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
