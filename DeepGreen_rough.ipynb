{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28dbb055",
   "metadata": {
    "id": "28dbb055"
   },
   "source": [
    "# APPM 5720 DeepGreen Example Notebook\n",
    "#### Paper: DeepGreen: deep learning of Greenâ€™s functions for nonlinear boundary value problems\n",
    "#### Paper by: Craig R. Gin, Daniel E. Shea, Steven L. Brunton, and J. Nathan Kutz\n",
    "#### Notebook by: Rey Koki and Mike McCabe\n",
    "\n",
    "This notebook walks through the nonlinear Poisson problem from _DeepGreen_. Several steps are slightly simplified from the original code, which can be found here: https://github.com/sheadan/DeepGreen, since we're only implementing one example and do not need the fully general code. We also make a few small departures for efficiency/speed purposes. These will be pointed out when they come up.\n",
    "\n",
    "## Nonlinear Poisson\n",
    "\n",
    "Put the problem description here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "083b497f",
   "metadata": {
    "id": "083b497f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used gpu\n"
     ]
    }
   ],
   "source": [
    "# Imports!\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.random as rnd\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "import flax.linen as nn\n",
    "import functools\n",
    "import matplotlib.pyplot as plt\n",
    "from flax.training import train_state\n",
    "from flax.metrics import tensorboard\n",
    "from random import shuffle\n",
    "from typing import Sequence, Callable, Any, Optional, Dict\n",
    "from jax.lib import xla_bridge\n",
    "print('Device used', xla_bridge.get_backend().platform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcb43d8",
   "metadata": {
    "id": "bfcb43d8"
   },
   "source": [
    "## Defining the Neural Network\n",
    "\n",
    "Here we define the neural network. Here, we use the Flax library built on top of JAX. JAX is an automatic differentiation and linear algebra acceleration library developed by Google. The API is intended to mimic numpy, though it has the added capability for functional transformations like computing gradients, automatically vectorizing code, or just-in-time (JIT) compiling it down to XLA code.\n",
    "\n",
    "Flax tends to have quite a bit of complexity hidden behind the scenes which makes it a bit harder to use than comparable libraries like PyTorch. Looking through the code below, it might seem like some things are being instantiated every time the model is called, but in practice, these objects are traced when they are instantiated and the actual object being behaves slightly differently. \n",
    "\n",
    "The model itself consists of two sets of encoders/decoders with the linear operator acting as a coupling mechanism in the encoding space. We start off by defining the Encoder and Decoder templates:\n",
    "\n",
    "__We didn't directly parameterize the encoder/decoders in DeepGreen for this demo, so to adjust the layers/depth/activations you'll have to do it directly (or adjust the code to pass parameters to the inner modules. If you adjust the layer count, you also need to adjust the downsampling factor in GreenNet to use custom resolutions (values of n).__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d06c81cc",
   "metadata": {
    "id": "d06c81cc"
   },
   "outputs": [],
   "source": [
    "class Conv2DEncoder(nn.Module):\n",
    "    # This is a DataClass, so these implicitly define init parameters\n",
    "    num_filters: Sequence[int] = (8, 16, 32, 64)\n",
    "    conv_window: Sequence[int] = (4, 4)\n",
    "    conv_strides: int = (1,1)\n",
    "    conv_padding: str = 'SAME'\n",
    "    pool_window: Sequence[int] = (2, 2)\n",
    "    pool_strides: int = (2,2)\n",
    "    pool_padding: str = 'VALID'\n",
    "    act_fn: Callable = nn.relu\n",
    "    add_init_fin: bool = True\n",
    "        \n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        inputs = x[:] # Save copy of inputs for residual        \n",
    "        for i, filters in enumerate(self.num_filters):\n",
    "            if i > 0:\n",
    "                x = nn.avg_pool(x, window_shape=self.pool_window,\n",
    "                                strides=self.pool_strides,\n",
    "                               padding=self.pool_padding)\n",
    "            x = nn.Conv(features=filters, kernel_size=self.conv_window,\n",
    "                       strides=self.conv_strides, padding=self.conv_padding)(x)\n",
    "            x = self.act_fn(x)\n",
    "            # If residual included, add projected inputs\n",
    "        if self.add_init_fin:\n",
    "            inputs = nn.Conv(features=self.num_filters[-1], \n",
    "                        kernel_size=(2**(len(self.num_filters)-1),)*2,\n",
    "                         strides=(2**(len(self.num_filters)-1),)*2,\n",
    "                        padding='VALID')(inputs)\n",
    "\n",
    "            x += inputs\n",
    "        return x.reshape(x.shape[0], -1)\n",
    "                \n",
    "    \n",
    "class Conv2DDecoder(nn.Module):\n",
    "    init_size: Sequence[int] = (16, 16, 64)\n",
    "    output_size: Sequence[int] = (-1, 128, 128)\n",
    "    num_filters: Sequence[int] = (32, 16, 8)\n",
    "    conv_window: Sequence[int] = (4, 4)\n",
    "    conv_strides:int = (2,2)\n",
    "    conv_padding: str = 'SAME'\n",
    "    act_fn: Callable = nn.relu\n",
    "    add_init_fin: bool = True\n",
    "        \n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = x.reshape(-1, *self.init_size)\n",
    "        inputs = x[:]\n",
    "        for filters in self.num_filters:\n",
    "            x = nn.ConvTranspose(features=filters, kernel_size=self.conv_window,\n",
    "                                 strides=self.conv_strides, padding=self.conv_padding)(x)\n",
    "            x = self.act_fn(x)\n",
    "        # Do one last small convolution\n",
    "        x = nn.ConvTranspose(features=1,\n",
    "                             kernel_size=self.conv_window,\n",
    "                            strides=(1,1),\n",
    "                            padding=self.conv_padding)(x).squeeze(-1)\n",
    "        \n",
    "        # Note this a departure from the actual paper code\n",
    "        # which just reshapes the encoder space to add. Since\n",
    "        # that makes no sense (it's like trying to add a smaller color\n",
    "        # image to a larger greyscale image by shifting the RGB values to different\n",
    "        # pixels to make the shapes line up), we've swapped to standard upsampling\n",
    "        if self.add_init_fin:\n",
    "            inputs = nn.Conv(features=1, kernel_size=(1, 1))(inputs).squeeze(-1)\n",
    "            inputs = jax.image.resize(inputs, shape=(inputs.shape[0], *self.output_size[1:]), method='linear')\n",
    "            x += inputs\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634377d0",
   "metadata": {
    "id": "634377d0"
   },
   "source": [
    "Once the encoders and decoders are built, the full model just connects the encoder/decoder pairs through a few linear projections and the linear operator. The sequential linear operations are a little unconventional as these are essentially a single low-rank linear operator though with the coupling $Lv=f$/$L^{-1}f=v$ promoted by the loss function.\n",
    "\n",
    "Note that we return all values included in loss functions. In applications, one would likely only be using the trained model to infer $u$ from $f$ and as such would not require all outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50eb2a30",
   "metadata": {
    "id": "50eb2a30"
   },
   "outputs": [],
   "source": [
    "class GreenNet(nn.Module):\n",
    "    # Note, since we're only doing the nonlinear Poisson example,\n",
    "    # we removed some of the parameterization here to simplify things\n",
    "    n: int = 128\n",
    "    units_latent: int = 200    \n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, inputs):\n",
    "        u, F = inputs\n",
    "        \n",
    "        # Let's define our modules. Since we reuse them, it probably would have\n",
    "        # made more sense to not use nn.compact and just use a setup function\n",
    "        # but it is too late now. This is getting traced anyway,\n",
    "        # so it doesn't actually matter apart from looking a bit clunky.\n",
    "        u_encoder = Conv2DEncoder()\n",
    "        u_decoder = Conv2DDecoder(output_size=(-1, self.n, self.n), init_size=(self.n//8, self.n//8, 64))\n",
    "        v_reducer = nn.Dense(self.units_latent)\n",
    "        v_expander = nn.Dense(self.n**2)\n",
    "        \n",
    "        F_encoder = Conv2DEncoder()\n",
    "        F_decoder = Conv2DDecoder(output_size=(-1, self.n, self.n), init_size=(self.n//8, self.n//8, 64))\n",
    "        f_reducer = nn.Dense(self.units_latent)\n",
    "        f_expander = nn.Dense(self.n**2)\n",
    "        \n",
    "        operator = self.param('Operator', init_fn=lambda key: jnp.eye(self.units_latent)*1.)\n",
    "\n",
    "        # Autoencode u\n",
    "        u_encoded = u_encoder(u)\n",
    "        # I guess this avoids doing a large dense matrix inverse\n",
    "        v = v_reducer(u_encoded)\n",
    "        v_exp = v_expander(v)\n",
    "        u_decoded = u_decoder(v_exp)\n",
    "        \n",
    "        # Autoencode F\n",
    "        F_encoded = F_encoder(F)\n",
    "        f = f_reducer(F_encoded)\n",
    "        f_exp = f_expander(f)\n",
    "        F_decoded = F_decoder(f_exp)  \n",
    "        \n",
    "        # L things - seems kind of wasteful, but L is small\n",
    "        L_upper = jnp.triu(operator)\n",
    "        L = .5*(L_upper+L_upper.T)\n",
    "        \n",
    "        # Forward model\n",
    "        Lv = jax.lax.dot_general(v, L,\n",
    "                                 (((v.ndim - 1,), (0,)), ((), ())),)\n",
    "        Lv_exp = f_expander(Lv)\n",
    "        Lv_decoded = F_decoder(Lv_exp)\n",
    "        \n",
    "        # Inverse model\n",
    "        Linvf = jnp.linalg.solve(jnp.expand_dims(L, 0), f)\n",
    "        Linvf_exp = f_expander(Linvf)\n",
    "        Linvf_decoded = F_decoder(Linvf_exp)\n",
    "        \n",
    "        return u_decoded, F_decoded, Lv_decoded, Linvf_decoded, f, v, Lv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dff1b0",
   "metadata": {
    "id": "55dff1b0"
   },
   "source": [
    "## Building the data set\n",
    "\n",
    "We handle data a bit differently from the paper to avoid forcing everyone to download several GB of data. The paper generated data by sampling forcing functions and using an external solver to generate solutions. This is time consuming and doesn't actually compute the exact loss. We instead use the Method of Manufactured Solutions (MMS) so that we can generate solutions and forcings in real time.\n",
    "\n",
    "As opposed to computing true solutions for given forcings, in MMS, you sample solutions and compute the forcing by applying the differential operator to the solution. While this doesn't always result in realistic problems and generally requires smooth solutions, it is much, much faster and more accurate than generating data from numerical solvers. The downside is that using their forcings as solutions breaks boundary conditions which isn't ideal given the proposal is to learn a Green's function in the encoder space, so we changed some of the functions up to ensure homogeneous BCs. \n",
    "\n",
    "This data API here is a little weird - the original version was too slow for demo purposes, so the final version is a mix between the original version (which used a more standard data API) and a JIT-friendly data API. The test/train split components are the main victims here as they ultimately got hard-coded with some unnecessary storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd143ed1",
   "metadata": {
    "id": "bd143ed1"
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "def nlp_operator(u):\n",
    "    \"\"\" Transforms function by applying the nonlinear Poisson operator:\n",
    "      \n",
    "        Pu = -\\nabla \\dot ((1+u^2)\\nabla u)\n",
    "    \"\"\"\n",
    "    flux = lambda x: (1+u(x)**2)*(jax.grad(u)(x))\n",
    "    return lambda x: (-jax.jacfwd(flux)(x)*jnp.eye(2)).sum()\n",
    "    \n",
    "def jax_collate(batch):\n",
    "    if isinstance(batch[0], jnp.DeviceArray):\n",
    "        return jnp.stack(batch)\n",
    "    elif isinstance(batch[0], (tuple,list)):\n",
    "        transposed = zip(*batch)\n",
    "        return [jax_collate(samples) for samples in transposed]\n",
    "    else:\n",
    "        return jnp.array(batch)\n",
    "    \n",
    "def NLP_Dataset_Sampler(n=128, batch_size=64, cubic=False, train=True, valid=False, test=False):\n",
    "    \"\"\" Factory for building data samplers for training.\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    n ~ int: Number of grid points in the x and y directions\n",
    "    batch size ~ int: Examples per batch.\n",
    "    cubic ~ bool: Indicator whether to sample from the cubic space\n",
    "    train ~ bool: Indicator whether to use the train indices\n",
    "    valid ~ bool: Indicator whether to use the validation indices\n",
    "    test ~ bool: Indicator whether to use the (non-cubic) test indices\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    sampler ~ Callable: takes in indices and returns data\n",
    "    len_func ~ Callable: zero parameter function that returns the dataset size.\n",
    "    \"\"\"\n",
    "    ##### u, F Builder Functions ######\n",
    "    def gamma(k):\n",
    "        return .01 +.28*k/3\n",
    "              \n",
    "    def build_gaussian(params):\n",
    "        # Just multiplied by sin to get BCs\n",
    "        a, bx, by, c = params\n",
    "        u = lambda x: .01*a*jnp.exp((-(x[0]-bx)**2 - (x[1]-by)**2)/(2*c**2))*jnp.sin(.5*x[0])*jnp.sin(.5*x[1])\n",
    "        F = nlp_operator(u)\n",
    "        Um, Fm = jax.vmap(u), jax.vmap(F)\n",
    "        return Um(coords), Fm(coords)\n",
    "    \n",
    "    def build_cosine(params):\n",
    "        # Actually sines\n",
    "        alpha, betax, betay, _ = params \n",
    "        u = lambda x: .01*alpha*jnp.sin(betax*x[0])*jnp.sin(betay*x[1])\n",
    "        F = nlp_operator(u)\n",
    "        Um, Fm = jax.vmap(u), jax.vmap(F)\n",
    "        return Um(coords), Fm(coords)\n",
    "    \n",
    "    \n",
    "    def build_cubic1(params):\n",
    "        # Moved 0s\n",
    "        kx, ky, _, _ = params\n",
    "        u = lambda x: .01*(kx*(x[0]-jnp.pi)*(x[0]-2*jnp.pi)*x[0] \\\n",
    "                        + ky*(x[1]-jnp.pi)*(x[1]-2*jnp.pi)*x[1])\n",
    "        F = nlp_operator(u)\n",
    "        Um, Fm = jax.vmap(u), jax.vmap(F)\n",
    "        return Um(coords), Fm(coords)\n",
    "    \n",
    "    def build_cubic2(params):\n",
    "        # Moved 0s and removed psi\n",
    "        kx, ky, zetax, zetay = params\n",
    "        u = lambda x: .01*(kx*(x[0]-jnp.pi)*(x[0]-2*jnp.pi)*x[0] + ky*(x[1]-jnp.pi)*(x[1]-2*jnp.pi)*x[1] \\\n",
    "                        + zetax*(x[0]-2*jnp.pi)*x[0] + zetay*(x[1]-2*jnp.pi)*x[1])\n",
    "        F = nlp_operator(u)\n",
    "        Um, Fm = jax.vmap(u), jax.vmap(F)\n",
    "        return Um(coords), Fm(coords)\n",
    "\n",
    "    ##### Actual Sampling functions #####\n",
    "    def get_len():\n",
    "        return len(data)\n",
    "    \n",
    "    def get_item(idx):\n",
    "        sub = data[idx]\n",
    "        func_build, params = sub[0], sub[1:]\n",
    "        u, F = jax.lax.switch(func_build.astype(int), [build_gaussian, build_cosine,\n",
    "                                                      build_cubic1, build_cubic2], params) \n",
    "        return u.reshape(n, n, 1), F.reshape(n, n, 1)\n",
    "    \n",
    "    sample = jax.vmap(get_item)\n",
    "    \n",
    "    # Build shared state for all inner functions\n",
    "    if not cubic:\n",
    "        # Set up Gaussians\n",
    "        a_range = jnp.arange(-25, 26., 5)\n",
    "        b_range = jnp.arange(jnp.pi/3, 5*jnp.pi/3+.01, jnp.pi/3)\n",
    "        c_range = jnp.arange(.1, 5, .2)\n",
    "        gauss_params = [(0.,)+ p for p in product(a_range, b_range, b_range, c_range)]\n",
    "\n",
    "        alpha_range = jnp.arange(1, 10.1, .1)\n",
    "        beta_range = jnp.arange(1, 5.1, .5)\n",
    "        cosine_params = [(1.,)+ p+(0,) \n",
    "                         for p in product(alpha_range, beta_range, beta_range)]\n",
    "\n",
    "        total_params = gauss_params + cosine_params\n",
    "        shuffle(total_params)\n",
    "\n",
    "        # Hard coding the values from the paper even though it's not the same\n",
    "        if train:\n",
    "            data = total_params[:9806]\n",
    "        elif valid:\n",
    "            data = total_params[9806:9806+2452]\n",
    "        else:\n",
    "            data = total_params[9806+2452:]\n",
    "\n",
    "    else:\n",
    "        k = gamma(jnp.array([0, 1, 2, 3]))\n",
    "#         psi = jnp.arange(-5, 6., 1)\n",
    "        zeta = jnp.arange(.01, .26, .6)\n",
    "        cubic1_params = [(2.,) + p+(0,0)\n",
    "                       for p in product(k, k)]\n",
    "        cubic2_params = [(3.,) + p\n",
    "                       for p in product(k, k, zeta, zeta)]\n",
    "        data = cubic1_params + cubic2_params\n",
    "\n",
    "    data = jnp.array(data)\n",
    "    # Build the mesh once and reuse\n",
    "    xx, yy = jnp.meshgrid(jnp.linspace(0, 2*jnp.pi, n), jnp.linspace(0, 2*jnp.pi, n))\n",
    "    coords = jnp.stack([xx, yy], -1).reshape(-1, 2)\n",
    "    \n",
    "    return jax.jit(sample), get_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c717765",
   "metadata": {
    "id": "2c717765"
   },
   "source": [
    "## Setting up the run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a538548",
   "metadata": {
    "id": "7a538548"
   },
   "source": [
    "Now we'll define the training loops. The paper uses multiple parallel runs and takes the best performing models. This is going to be running on Colab so you are not going to have the hardware for that. Instead, we're just going to train a single model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f560cf10",
   "metadata": {
    "id": "f560cf10"
   },
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def update_params(state, grads):\n",
    "    return state.apply_gradients(grads=grads)\n",
    "\n",
    "        \n",
    "@jax.jit\n",
    "def compute_losses(u, F, u_decoded, F_decoded, Lv_decoded, Linvf_decoded, f, v, Lv, eps=1e-5):\n",
    "    \"\"\" Computes the 6 Normalized MSEs from the paper.\n",
    "    \n",
    "    Note: the use of means instead of sums in computing squared norms is from the paper\n",
    "    code. They also sum over batches. This doesn't matter that much, but it does adjust the weighting a bit, \n",
    "    so we manually re-weight to account for it.\n",
    "    \"\"\"\n",
    "    # Loss 1 - Reconstruction u\n",
    "    loss1 = (((u_decoded - u)**2).mean((1, 2)) / ((u**2).mean((1,2))+eps)).mean()\n",
    "    # Loss 2 - Reconstruction f \n",
    "    loss2 = (((F_decoded - F)**2).mean((1, 2)) / ((F**2).mean((1,2))+eps)).mean()\n",
    "    # Loss 3 - Forward in encoded space - don't love the gradient dynamics of dividing here\n",
    "    loss3 = (((Lv - f)**2).mean(-1) / ((f**2).mean(-1)+eps)).mean()\n",
    "    # Loss 4 - \"Superposition\" loss - seems like it would just change the relative weight of loss 3 \n",
    "    # in a weird non-convex way and penalize the magnitude of the encoded vectors. Doesn't seem like \n",
    "    # a great idea, but it is in the paper\n",
    "    loss4 = 0.\n",
    "    # Loss 5 - Forward operator loss\n",
    "    loss5 = (((Lv_decoded - F)**2).mean((1, 2)) / ((F**2).mean((1,2))+eps)).mean()\n",
    "    # Loss 6 - Backwards operator loss\n",
    "    loss6 = (((Linvf_decoded - u)**2).mean((1, 2)) / ((u**2).mean((1,2))+eps)).mean()\n",
    "    return loss1, loss2, loss3, loss4, loss5, loss6\n",
    "\n",
    "@functools.partial(jax.jit, static_argnums=(0, 2, 4, 5))\n",
    "def train_epoch(model, state, data, perms, num_batches, eval_full=True):\n",
    "    # JIT is touchy around conditionals (the trace notes the first path), so this just says compile\n",
    "    #  again if the conditional changes. \n",
    "    @functools.partial(jax.jit)\n",
    "    def grad_step(state, perm):\n",
    "        def loss_fn(params):\n",
    "            # Run model\n",
    "            u_decoded, F_decoded, Lv_decoded, Linvf_decoded, f, v, Lv = model.apply({'params':params}, batch)\n",
    "            u, F = batch\n",
    "            u, F = u.squeeze(-1), F.squeeze(-1)\n",
    "            loss1, loss2, loss3, loss4, loss5, loss6 = compute_losses(u, F, u_decoded, F_decoded, \n",
    "                                                                      Lv_decoded, Linvf_decoded, f, v, Lv)\n",
    "            # We're keeping all the losses for logging, but the total loss is only the reconstruction\n",
    "            # losses at the beginning of training\n",
    "            if eval_full:\n",
    "                return loss1+loss2+loss3+loss4+loss5+loss6, (loss1, loss2, loss3, loss4, loss5, loss6)\n",
    "            else:\n",
    "                return loss1+loss2, (loss1, loss2, loss3, loss4, loss5, loss6)\n",
    "        \n",
    "        batch = data(perm)\n",
    "        grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "        (train_loss, aux_losses), grads = grad_fn(state.params)\n",
    "        state = update_params(state, grads)\n",
    "        return state, aux_losses\n",
    "\n",
    "    # Run actual code - Carries and updates state every batch\n",
    "    # returns final state and accumulated outputs (losses)\n",
    "    state, aux_loss_means = jax.lax.scan(grad_step, state, perms)\n",
    "    return state, [jnp.mean(l) for l in aux_loss_means]   \n",
    "\n",
    "def validation_run(model, state, data, batch_size, num_batches):\n",
    "    # Only difference is we do not compute the gradient and update the state here\n",
    "    @functools.partial(jax.jit)\n",
    "    def exec_step(state, perm):\n",
    "        # Run model\n",
    "        batch = data(perm)\n",
    "        u_decoded, F_decoded, Lv_decoded, Linvf_decoded, f, v, Lv = model.apply({'params':state.params}, batch)\n",
    "        u, F = batch\n",
    "        u, F = u.squeeze(-1), F.squeeze(-1)\n",
    "        loss1, loss2, loss3, loss4, loss5, loss6 = compute_losses(u, F, u_decoded, F_decoded, \n",
    "                                                                  Lv_decoded, Linvf_decoded, f, v, Lv)        \n",
    "        return state, (loss1, loss2, loss3, loss4, loss5, loss6)\n",
    "    perms = jnp.arange(batch_size*num_batches).reshape(num_batches, batch_size)\n",
    "    state, aux_loss_means = jax.lax.scan(exec_step, state, perms)\n",
    "    return aux_loss_means\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7592d8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model run parameters\n",
    "aec_only_epochs = 75\n",
    "full_epochs = 2500\n",
    "batch_size = 64\n",
    "n= 32\n",
    "\n",
    "# Content doesn't matter so we're just chosing a convenient shape\n",
    "init_vals = jnp.array(np.random.uniform(size=(10, n, n, 1)))\n",
    "\n",
    "# JAX's random is kind of a pain, but it makes more sense when you're doing distributed training\n",
    "# which we are not doing here. \n",
    "key = rnd.PRNGKey(0)\n",
    "key, use_key = rnd.split(key, 2)\n",
    "\n",
    "model = GreenNet(n=n)\n",
    "params = model.init(use_key, (init_vals, init_vals))\n",
    "\n",
    "# JAX is a functional framework, but Deep Learning has historically used mostly object oriented libraries.\n",
    "# TrainState is a helper for organizing the model parameters and state so the training loop can be written \n",
    "# more like OOP code.\n",
    "\n",
    "# We're using the AdamW optimizer as the paper uses Adam with weight decay. \n",
    "state = train_state.TrainState.create(apply_fn=model.apply,\n",
    "                                     params = params['params'],\n",
    "                                     tx=optax.adamw(learning_rate=1e-3, weight_decay=1e-6))\n",
    "\n",
    "# Load up on datasets - the len funcs instead of objects were just a mistake\n",
    "train_dataset, train_len_func = NLP_Dataset_Sampler(n=n, batch_size=batch_size)\n",
    "valid_dataset, valid_len_func = NLP_Dataset_Sampler(n=n, batch_size=batch_size, train=False, test=True)\n",
    "test_dataset, test_len_func = NLP_Dataset_Sampler(n=n, batch_size=batch_size, train=False, test=True)\n",
    "cubic_test_dataset, cubic_len_func = NLP_Dataset_Sampler(n=n, batch_size=batch_size, cubic=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76d99c6",
   "metadata": {},
   "source": [
    "Before we train the model, let's look in at what functions we're trying to learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7e413d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "u, F = train_dataset(jnp.array([1, 11]))\n",
    "\n",
    "fig = plt.figure(constrained_layout=True, figsize=(6,6))\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 6))\n",
    "axes[0][0].set_title('u Values')\n",
    "axes[0][1].set_title('F Values')\n",
    "aa = axes[0][0].imshow(u[0])\n",
    "plt.colorbar(aa, ax=axes[0][0])\n",
    "ab = axes[0][1].imshow(F[0])\n",
    "plt.colorbar(ab, ax=axes[0][1])\n",
    "ac = axes[1][0].imshow(u[1])\n",
    "plt.colorbar(ac, ax=axes[1][0])\n",
    "ad = axes[1][1].imshow(F[1])\n",
    "plt.colorbar(ad, ax=axes[1][1])\n",
    "plt.title('Training Samples')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3141216a",
   "metadata": {},
   "source": [
    "These functions seem a bit harder due to varying scales compared to the paper problems, which from observing their \"hardest\" problems by loss, seemed to have generally had forcings and solutions on the same scale. In our case, there might be several orders of magnitude difference between the two. This makes the optimization problem a bit harder as we'd like all of our losses to have similar magnitude, but that's not going to be possible here without careful reweighting. We had to manually scale them down to reduce the magnitude gaps within individual solutions and forcings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c22967a",
   "metadata": {},
   "source": [
    "## Running the Model\n",
    "\n",
    "Now all that's left is training the model. On the colab GPU with $n=128$ (the setting from the paper), this will take far longer than this class. You can either reduce the size (make sure it's a multiple of 16) or try training and skip ahead to the next section where you can use a pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "17671bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 22907), started 0:19:04 ago. (Use '!kill 22907' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-2bc03f44ef7492be\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-2bc03f44ef7492be\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3f7d96ab",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "3f7d96ab",
    "outputId": "6ba0e227-d59d-4c74-fbdf-60cfef8b5f72",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [DeviceArray(0.4261202, dtype=float32), DeviceArray(0.3129032, dtype=float32), DeviceArray(1.5759465, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(1.0771992, dtype=float32), DeviceArray(161.54889, dtype=float32)]\n",
      "1 [DeviceArray(0.03226293, dtype=float32), DeviceArray(0.04709037, dtype=float32), DeviceArray(1.605792, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(1.0852604, dtype=float32), DeviceArray(268.3628, dtype=float32)]\n",
      "2 [DeviceArray(0.01624302, dtype=float32), DeviceArray(0.03771617, dtype=float32), DeviceArray(1.5835305, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(1.0706524, dtype=float32), DeviceArray(269.591, dtype=float32)]\n",
      "3 [DeviceArray(0.01290627, dtype=float32), DeviceArray(0.02983182, dtype=float32), DeviceArray(1.6126096, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(1.0740658, dtype=float32), DeviceArray(270.28397, dtype=float32)]\n",
      "4 [DeviceArray(0.01386654, dtype=float32), DeviceArray(0.02854812, dtype=float32), DeviceArray(1.7755259, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(1.1140454, dtype=float32), DeviceArray(271.7374, dtype=float32)]\n",
      "5 [DeviceArray(0.00750216, dtype=float32), DeviceArray(0.02934509, dtype=float32), DeviceArray(1.7449367, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(1.1197349, dtype=float32), DeviceArray(271.63022, dtype=float32)]\n",
      "6 [DeviceArray(0.00616016, dtype=float32), DeviceArray(0.02360259, dtype=float32), DeviceArray(1.7358143, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(1.1215776, dtype=float32), DeviceArray(272.36368, dtype=float32)]\n",
      "7 [DeviceArray(0.00759654, dtype=float32), DeviceArray(0.02611109, dtype=float32), DeviceArray(1.6469651, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(1.1027906, dtype=float32), DeviceArray(272.5978, dtype=float32)]\n",
      "8 [DeviceArray(0.00646371, dtype=float32), DeviceArray(0.03777626, dtype=float32), DeviceArray(1.677369, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(1.0933692, dtype=float32), DeviceArray(272.26926, dtype=float32)]\n",
      "9 [DeviceArray(0.00519486, dtype=float32), DeviceArray(0.02244007, dtype=float32), DeviceArray(1.5896728, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(1.076547, dtype=float32), DeviceArray(272.86615, dtype=float32)]\n",
      "10 [DeviceArray(0.00589305, dtype=float32), DeviceArray(0.02058486, dtype=float32), DeviceArray(1.612084, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(1.0834336, dtype=float32), DeviceArray(273.68573, dtype=float32)]\n",
      "11 [DeviceArray(0.01033185, dtype=float32), DeviceArray(0.02000755, dtype=float32), DeviceArray(1.795681, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(1.1259251, dtype=float32), DeviceArray(273.7682, dtype=float32)]\n",
      "12 [DeviceArray(0.00510135, dtype=float32), DeviceArray(0.01948043, dtype=float32), DeviceArray(1.8314626, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(1.1361588, dtype=float32), DeviceArray(274.7548, dtype=float32)]\n",
      "13 [DeviceArray(0.00387242, dtype=float32), DeviceArray(0.01913592, dtype=float32), DeviceArray(1.7658616, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(1.1160057, dtype=float32), DeviceArray(275.20657, dtype=float32)]\n",
      "14 [DeviceArray(0.00428994, dtype=float32), DeviceArray(0.02366587, dtype=float32), DeviceArray(1.5952656, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(1.088799, dtype=float32), DeviceArray(276.17044, dtype=float32)]\n",
      "15 [DeviceArray(0.00423962, dtype=float32), DeviceArray(0.01979632, dtype=float32), DeviceArray(1.4515691, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(1.0821916, dtype=float32), DeviceArray(276.26038, dtype=float32)]\n",
      "16 [DeviceArray(0.00555125, dtype=float32), DeviceArray(0.01824491, dtype=float32), DeviceArray(1.5117995, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(1.0845524, dtype=float32), DeviceArray(278.29498, dtype=float32)]\n",
      "17 [DeviceArray(0.00421334, dtype=float32), DeviceArray(0.01733358, dtype=float32), DeviceArray(1.5976913, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(1.0973802, dtype=float32), DeviceArray(279.6753, dtype=float32)]\n",
      "18 [DeviceArray(0.00504356, dtype=float32), DeviceArray(0.01736276, dtype=float32), DeviceArray(1.5660735, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(1.073791, dtype=float32), DeviceArray(283.97812, dtype=float32)]\n",
      "19 [DeviceArray(0.00535296, dtype=float32), DeviceArray(0.01595623, dtype=float32), DeviceArray(1.6530474, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(1.0874472, dtype=float32), DeviceArray(286.38895, dtype=float32)]\n",
      "20 [DeviceArray(0.00344109, dtype=float32), DeviceArray(0.01440293, dtype=float32), DeviceArray(1.576376, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(1.0669179, dtype=float32), DeviceArray(291.21463, dtype=float32)]\n",
      "21 [DeviceArray(0.00314289, dtype=float32), DeviceArray(0.01301447, dtype=float32), DeviceArray(1.4411232, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(1.0478448, dtype=float32), DeviceArray(296.60056, dtype=float32)]\n",
      "22 [DeviceArray(0.0046487, dtype=float32), DeviceArray(0.01233219, dtype=float32), DeviceArray(1.4209906, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(1.0427322, dtype=float32), DeviceArray(301.07812, dtype=float32)]\n",
      "23 [DeviceArray(0.00352225, dtype=float32), DeviceArray(0.00897834, dtype=float32), DeviceArray(1.4109881, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(1.0366532, dtype=float32), DeviceArray(305.4859, dtype=float32)]\n",
      "24 [DeviceArray(0.00327749, dtype=float32), DeviceArray(0.00690864, dtype=float32), DeviceArray(1.3835641, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(1.0256425, dtype=float32), DeviceArray(308.5203, dtype=float32)]\n",
      "25 [DeviceArray(0.00431632, dtype=float32), DeviceArray(0.05250655, dtype=float32), DeviceArray(1.2233456, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(0.99965435, dtype=float32), DeviceArray(304.2848, dtype=float32)]\n",
      "26 [DeviceArray(0.00923544, dtype=float32), DeviceArray(0.01134558, dtype=float32), DeviceArray(1.1125548, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(0.96098775, dtype=float32), DeviceArray(309.55417, dtype=float32)]\n",
      "27 [DeviceArray(0.00650575, dtype=float32), DeviceArray(0.00658937, dtype=float32), DeviceArray(1.1963907, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(0.9851989, dtype=float32), DeviceArray(312.22775, dtype=float32)]\n",
      "28 [DeviceArray(0.00255662, dtype=float32), DeviceArray(0.00517655, dtype=float32), DeviceArray(1.2023759, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(0.98799324, dtype=float32), DeviceArray(313.55417, dtype=float32)]\n",
      "29 [DeviceArray(0.00242405, dtype=float32), DeviceArray(0.00492712, dtype=float32), DeviceArray(1.2059879, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(0.9886739, dtype=float32), DeviceArray(313.13055, dtype=float32)]\n",
      "30 [DeviceArray(0.00238621, dtype=float32), DeviceArray(0.00458402, dtype=float32), DeviceArray(1.2087351, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(0.9877737, dtype=float32), DeviceArray(312.32986, dtype=float32)]\n",
      "31 [DeviceArray(0.00274006, dtype=float32), DeviceArray(0.00414181, dtype=float32), DeviceArray(1.2123909, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(0.9884562, dtype=float32), DeviceArray(315.3494, dtype=float32)]\n",
      "32 [DeviceArray(0.00256824, dtype=float32), DeviceArray(0.00389088, dtype=float32), DeviceArray(1.2210017, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(0.9899739, dtype=float32), DeviceArray(315.29156, dtype=float32)]\n",
      "33 [DeviceArray(0.00261486, dtype=float32), DeviceArray(0.00404088, dtype=float32), DeviceArray(1.2208651, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(0.9871715, dtype=float32), DeviceArray(314.82822, dtype=float32)]\n",
      "34 [DeviceArray(0.00290132, dtype=float32), DeviceArray(0.00398385, dtype=float32), DeviceArray(1.2441231, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(0.9916186, dtype=float32), DeviceArray(315.5946, dtype=float32)]\n",
      "35 [DeviceArray(0.0037593, dtype=float32), DeviceArray(0.00374448, dtype=float32), DeviceArray(1.3087478, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(1.0055438, dtype=float32), DeviceArray(315.58932, dtype=float32)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 [DeviceArray(0.00313713, dtype=float32), DeviceArray(0.00430893, dtype=float32), DeviceArray(1.3039116, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(1.0029007, dtype=float32), DeviceArray(316.4917, dtype=float32)]\n",
      "37 [DeviceArray(0.00280259, dtype=float32), DeviceArray(0.0033919, dtype=float32), DeviceArray(1.3214304, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(1.0023143, dtype=float32), DeviceArray(315.74054, dtype=float32)]\n",
      "38 [DeviceArray(0.00386949, dtype=float32), DeviceArray(0.00312827, dtype=float32), DeviceArray(1.3926713, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(1.0149574, dtype=float32), DeviceArray(315.4901, dtype=float32)]\n",
      "39 [DeviceArray(0.00468943, dtype=float32), DeviceArray(0.00346468, dtype=float32), DeviceArray(1.5026493, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(1.0351148, dtype=float32), DeviceArray(315.0604, dtype=float32)]\n",
      "40 [DeviceArray(0.00227367, dtype=float32), DeviceArray(0.0030922, dtype=float32), DeviceArray(1.4589362, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(1.0237014, dtype=float32), DeviceArray(316.7254, dtype=float32)]\n",
      "41 [DeviceArray(0.0023429, dtype=float32), DeviceArray(0.00336166, dtype=float32), DeviceArray(1.4513037, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(1.0196426, dtype=float32), DeviceArray(316.4312, dtype=float32)]\n",
      "42 [DeviceArray(0.00359899, dtype=float32), DeviceArray(0.00563612, dtype=float32), DeviceArray(1.4210628, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(1.0038438, dtype=float32), DeviceArray(317.0596, dtype=float32)]\n",
      "43 [DeviceArray(0.00283831, dtype=float32), DeviceArray(0.00287609, dtype=float32), DeviceArray(1.4788328, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(1.0199839, dtype=float32), DeviceArray(316.8571, dtype=float32)]\n",
      "44 [DeviceArray(0.00262413, dtype=float32), DeviceArray(0.00279983, dtype=float32), DeviceArray(1.4485831, dtype=float32), DeviceArray(0., dtype=float32), DeviceArray(1.0139585, dtype=float32), DeviceArray(317.98065, dtype=float32)]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21229/2303792617.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# Check the validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mvalid_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_bs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_nbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_21229/121252758.py\u001b[0m in \u001b[0;36mvalidation_run\u001b[0;34m(model, state, data, batch_size, num_batches)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mperms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux_loss_means\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexec_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0maux_loss_means\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/jax/_src/lax/control_flow.py\u001b[0m in \u001b[0;36mscan\u001b[0;34m(f, init, xs, length, reverse, unroll)\u001b[0m\n\u001b[1;32m   1633\u001b[0m                         init_tree, carry_avals)\n\u001b[1;32m   1634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1635\u001b[0;31m   out = scan_p.bind(*consts, *in_flat,\n\u001b[0m\u001b[1;32m   1636\u001b[0m                     \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1637\u001b[0m                     \u001b[0mnum_consts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconsts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_carry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/jax/_src/lax/control_flow.py\u001b[0m in \u001b[0;36mscan_bind\u001b[0;34m(*args, **params)\u001b[0m\n\u001b[1;32m   2210\u001b[0m     \u001b[0m_scan_typecheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mavals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2211\u001b[0m     \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_jaxpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'jaxpr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjaxpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2212\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAxisPrimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscan_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2214\u001b[0m \u001b[0mscan_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAxisPrimitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"scan\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/jax/core.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m   2039\u001b[0m     top_trace = (top_trace if not axis_main or axis_main.level < top_trace.level\n\u001b[1;32m   2040\u001b[0m                  else axis_main.with_cur_sublevel())\n\u001b[0;32m-> 2041\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind_with_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/jax/core.py\u001b[0m in \u001b[0;36mbind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbind_with_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiple_results\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfull_lower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/jax/core.py\u001b[0m in \u001b[0;36mprocess_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/jax/_src/dispatch.py\u001b[0m in \u001b[0;36mapply_primitive\u001b[0;34m(prim, *args, **params)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mapply_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m   \u001b[0;34m\"\"\"Impl rule that compiles and runs a single primitive 'prim' using XLA.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m   compiled_fun = xla_primitive_callable(prim, *unsafe_map(arg_spec, args),\n\u001b[0m\u001b[1;32m     93\u001b[0m                                         **params)\n\u001b[1;32m     94\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mcompiled_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/jax/_src/util.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trace_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_clear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_clear\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/jax/_src/util.py\u001b[0m in \u001b[0;36mcached\u001b[0;34m(_, *args, **kwargs)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlru_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/jax/_src/dispatch.py\u001b[0m in \u001b[0;36mxla_primitive_callable\u001b[0;34m(prim, *arg_specs, **params)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m   compiled = _xla_callable_uncached(lu.wrap_init(prim_fun), device, None,\n\u001b[0m\u001b[1;32m    112\u001b[0m                                     prim.name, donated_invars, *arg_specs)\n\u001b[1;32m    113\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mprim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiple_results\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/jax/_src/dispatch.py\u001b[0m in \u001b[0;36m_xla_callable_uncached\u001b[0;34m(fun, device, backend, name, donated_invars, *arg_specs)\u001b[0m\n\u001b[1;32m    167\u001b[0m def _xla_callable_uncached(fun: lu.WrappedFun, device, backend, name,\n\u001b[1;32m    168\u001b[0m                            donated_invars, *arg_specs):\n\u001b[0;32m--> 169\u001b[0;31m   return lower_xla_callable(fun, device, backend, name, donated_invars,\n\u001b[0m\u001b[1;32m    170\u001b[0m                             *arg_specs).compile().unsafe_call\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/jax/_src/profiler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mTraceAnnotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdecorator_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/jax/_src/dispatch.py\u001b[0m in \u001b[0;36mlower_xla_callable\u001b[0;34m(fun, device, backend, name, donated_invars, *arg_specs)\u001b[0m\n\u001b[1;32m    256\u001b[0m   \u001b[0mmodule_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"jit_{fun.__name__}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjax_enable_mlir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m     module = mlir.lower_jaxpr_to_module(\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosed_jaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplatform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         mlir.ReplicaAxisContext(axis_env), name_stack, donated_invars)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/jax/interpreters/mlir.py\u001b[0m in \u001b[0;36mlower_jaxpr_to_module\u001b[0;34m(module_name, jaxpr, platform, axis_context, name_stack, donated_args, replicated_args, arg_shardings, result_shardings)\u001b[0m\n\u001b[1;32m    446\u001b[0m         f\"{module_name}.{next(_module_unique_id)}\")\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# TODO(phawkins): represent units with zero buffers at the runtime level.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     lower_jaxpr_to_fun(\n\u001b[0m\u001b[1;32m    449\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"main\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpublic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace_units_with_dummy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0mreplace_tokens_with_dummy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicated_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreplicated_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/jax/interpreters/mlir.py\u001b[0m in \u001b[0;36mlower_jaxpr_to_fun\u001b[0;34m(ctx, name, jaxpr, public, replace_units_with_dummy, replace_tokens_with_dummy, replicated_args, arg_shardings, result_shardings, input_output_aliases)\u001b[0m\n\u001b[1;32m    591\u001b[0m     callee_name_stack = xla.extend_name_stack(ctx.name_stack,\n\u001b[1;32m    592\u001b[0m                                               xla.wrap_name(name, 'jit'))\n\u001b[0;32m--> 593\u001b[0;31m     out_vals = jaxpr_subcomp(ctx.replace(name_stack=callee_name_stack),\n\u001b[0m\u001b[1;32m    594\u001b[0m                              \u001b[0mjaxpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mir_constants\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m                              *args)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/jax/interpreters/mlir.py\u001b[0m in \u001b[0;36mjaxpr_subcomp\u001b[0;34m(ctx, jaxpr, consts, *args)\u001b[0m\n\u001b[1;32m    677\u001b[0m           \u001b[0mmodule_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m           avals_in=map(aval, eqn.invars), avals_out=map(aval, eqn.outvars))\n\u001b[0;32m--> 679\u001b[0;31m       ans = rule(rule_ctx, *map(_unwrap_singleton_ir_values, in_nodes),\n\u001b[0m\u001b[1;32m    680\u001b[0m                  **eqn.params)\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/jax/interpreters/mlir.py\u001b[0m in \u001b[0;36mf_lowered\u001b[0;34m(ctx, *args, **params)\u001b[0m\n\u001b[1;32m    712\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend_axis_env_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m       \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_to_jaxpr_dynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavals_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m     return jaxpr_subcomp(ctx.module_context, jaxpr, _ir_consts(consts),\n\u001b[0m\u001b[1;32m    715\u001b[0m                          *map(wrap_singleton_ir_values, args))\n\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/jax/interpreters/mlir.py\u001b[0m in \u001b[0;36mjaxpr_subcomp\u001b[0;34m(ctx, jaxpr, consts, *args)\u001b[0m\n\u001b[1;32m    677\u001b[0m           \u001b[0mmodule_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m           avals_in=map(aval, eqn.invars), avals_out=map(aval, eqn.outvars))\n\u001b[0;32m--> 679\u001b[0;31m       ans = rule(rule_ctx, *map(_unwrap_singleton_ir_values, in_nodes),\n\u001b[0m\u001b[1;32m    680\u001b[0m                  **eqn.params)\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/jax/_src/lax/control_flow.py\u001b[0m in \u001b[0;36m_while_lowering\u001b[0;34m(ctx, cond_jaxpr, body_jaxpr, cond_nconsts, body_nconsts, *args)\u001b[0m\n\u001b[1;32m    786\u001b[0m           name_stack=xla.extend_name_stack(ctx.module_context.name_stack,\n\u001b[1;32m    787\u001b[0m                                            'body'))\n\u001b[0;32m--> 788\u001b[0;31m       new_z = mlir.jaxpr_subcomp(body_ctx, body_jaxpr.jaxpr,\n\u001b[0m\u001b[1;32m    789\u001b[0m                                  \u001b[0m_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mir_constants\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody_jaxpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m                                  *(y + z))\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/jax/interpreters/mlir.py\u001b[0m in \u001b[0;36mjaxpr_subcomp\u001b[0;34m(ctx, jaxpr, consts, *args)\u001b[0m\n\u001b[1;32m    676\u001b[0m       rule_ctx = LoweringRuleContext(\n\u001b[1;32m    677\u001b[0m           \u001b[0mmodule_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m           avals_in=map(aval, eqn.invars), avals_out=map(aval, eqn.outvars))\n\u001b[0m\u001b[1;32m    679\u001b[0m       ans = rule(rule_ctx, *map(_unwrap_singleton_ir_values, in_nodes),\n\u001b[1;32m    680\u001b[0m                  **eqn.params)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/jax/_src/util.py\u001b[0m in \u001b[0;36msafe_map\u001b[0;34m(f, *args)\u001b[0m\n\u001b[1;32m     42\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'length mismatch: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0munzip2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Train housekeeping\n",
    "train_size = train_len_func()\n",
    "n_batches = train_size // batch_size\n",
    "\n",
    "#Validation housekeeping\n",
    "valid_size = valid_len_func()\n",
    "valid_bs = 512\n",
    "valid_nbatches = valid_size // valid_bs\n",
    "\n",
    "# General run things\n",
    "summary_writer = tensorboard.SummaryWriter('.')\n",
    "loss_names= ['L'+str(i) for i in range(1, 7)]\n",
    "key = rnd.PRNGKey(0)\n",
    "\n",
    "for i in range(full_epochs):\n",
    "    # Run the training epoch\n",
    "    key, use_key = rnd.split(key, 2)\n",
    "    perm = rnd.permutation(use_key, train_size)[:batch_size*n_batches].reshape(n_batches, batch_size)\n",
    "    state, train_loss = train_epoch(model, state, train_dataset, perm, n_batches, eval_full=i>aec_only_epochs)\n",
    "    for j, loss in enumerate(train_loss):\n",
    "        summary_writer.scalar('Train ' + loss_names[j], loss, i)\n",
    "        \n",
    "    # Check the validation set\n",
    "    valid_losses = validation_run(model, state, valid_dataset, valid_bs, valid_nbatches)\n",
    "\n",
    "    print(i, train_loss)\n",
    "#     _, test_loss = validation_run(state, valid_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714deaf7",
   "metadata": {},
   "source": [
    "## Experimenting with Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b198a8fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DeepGreen_rough.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
